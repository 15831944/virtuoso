 <chapter label="rdfandsparql.xml" id="rdfandsparql"><title>RDF Database and SPARQL</title>
<abstract>
<para>
Starting with version 4.5, Virtuoso provides built-in support for SPARQL, the standard query language for RDF and the semantic web.

Adoption of SPARQL with Virtuoso is effortless, as any  existing SQL client applications and stored procedures can take advantage of SPARQL simply by using it in the place of or inside SQL queries.  Additionally, Virtuoso offers the standard SPARQL protocol to HTTP clients.
</para>

<para>
This chapter discusses Virtuoso's RDF triple storage and query capabilities. This is divided into a discussion of the RDF data representation, the SPARQL and SQL API's, protocol support and standard compliance notes.
</para>
</abstract>
<sect1 id="rdfdatarepresentation"><title>Data Representation</title>
<para>This section covers how Virtuoso stores RDF triples. The IRI_ID built-in data type is introduced, along with the default table structures used for triple persistency.</para>
<sect2 id="rdfiriidtype"><title>IRI_ID Type</title>
<para>The central notion of RDF is the IRI, or URI, which serves as the globally unique label of named nodes. The subject and predicate of a triple are always IRI's and the object may be an IRI or any other XML Schema scalar data type. In any case, an IRI is always distinct from any instance of any other data type.</para>
<para>Virtuoso supports a native IRI_ID data type, internally an unsigned 32 bit integer value. When compared with other IRI's, the collation is as with unsigned 32 bit integers. An IRI_ID is never equal to any instance of any other type.</para>
<para>Thus, the object column of a table storing triples can be declared as ANY and IRI values will be distinguishable without recourse to any extra flag and IRI's will naturally occupy their own contiguous segment in the ANY type collation sequence. Indices can be defined over such columns. An IRI_ID is never automatically cast into any other type nor any other type into IRI_ID.</para>
<para>The functions iri_id_num (in i IRI_ID) and iri_id_from_num (in n INT) convert between signed 32 bit integers and IRI_ID's. The function isiri_id (in i any) returns nonzero if the argument is of type IRI_ID, zero otherwise.</para>
<para>The syntax for an IRI_ID literal is</para>
<programlisting>
#i&lt;nnn&gt;, where nnn is up to 10 decimal digits.
#i12345 is equal to iri_id_from_num (12345)
</programlisting>

<para>When received by a SQL client application, the ODBC driver or
interactive SQL will bind an IRI_ID to a character buffer, producing
the #innn syntax. When passing IRI_ID's from a client, one can pass an
integer and use the iri_id_from_num () function in the statement to
convert server side. A SQL client will normally not be exposed to
IRI_ID's since the SPARQL implementation returns IRI's in their text
form, not as internal id's. These will however be seen if reading the
internal tables directly.</para>

</sect2>
<sect2 id="rdftables"><title>RDF_QUAD and other tables</title>
<para>The main tables of the default RDF storage system are:</para>
<programlisting>
create table DB.DBA.RDF_QUAD (
  G IRI_ID,
  S IRI_ID,
  P IRI_ID,
  O any,
  primary key (G,S,P,O) );
create bitmap index RDF_QUAD_OGPS on DB.DBA.RDF_QUAD (O, G, P, S);
</programlisting>
<para>Each triple is represented by one row in RDF_QUAD.
The columns represent the graph, subject, predicate and object.
The IRI_ID type columns reference RDF_IRI, which translates the internal id to the external name of the IRI.
The O column is of type ANY.
If the O value is a non-string SQL scalar, such as a number or date or IRI, it is stored in its native binary representation.
If it is a "very short" string (20 characters or less), it is also stored "as is".
Long strings and RDF literal with non-default type or language are stored using special data type called "rdf_box".
Instance of rdf_box consists of data type, language, the content (or beginning characters of a long content).

and a possible reference to RDF_OBJ if the object is too long to be held in-line in this table or should be outlined for free-text indexing.
</para>
<programlisting>
create table DB.DBA.RDF_PREFIX (
  RP_NAME varchar primary key,
  RP_ID int not null unique );
create table DB.DBA.RDF_IRI (
  RI_NAME varchar primary key,
  RI_ID IRI_ID not null unique );
</programlisting>
<para>These two tables store a mapping between internal IRI id's and their external string form.
A memory-resident cache contains recently used IRIs to reduce access to this table.
Function id_to_iri (in id IRI_ID) returns the IRI by its ID.
Function iri_to_id (in iri varchar, in may_create_new_id) returns an IRI_ID for given string;
if the string is not used before as an IRI then either NULL is returned or a new ID is allocated, depending on the second argument.
</para>
<programlisting>
create table DB.DBA.RDF_OBJ (
  RO_ID integer primary key,
    RO_VAL varchar,
  RO_LONG long varchar,
  RO_DIGEST any
)
create index RO_VAL on DB.DBA.RDF_OBJ (RO_VAL)
create index RO_DIGEST on DB.DBA.RDF_OBJ (RO_DIGEST)
;
</programlisting>
<para>When an O value of RDF_QUAD is longer than a certain limit or should be free-text indexed, the value is stored in this table.
Depending on the length of the value, it goes into the varchar or the long varchar column.
The RO_ID is contained in rdf_box object that is stored in the O column.
Still, the truncated value of O can be used for determining equality and range matching,
even if &lt; and &gt; of closely matching values need to look at the real string in RDF_OBJ.
When RO_LONG is used to store very long value, RO_VAL contains a simple checksum of the value, to accelerate search for identical values when the table is populated by new values.
</para>
<programlisting>
create table DB.DBA.RDF_DATATYPE (
    RDT_IID IRI_ID not null primary key,
    RDT_TWOBYTE integer not null unique,
    RDT_QNAME varchar );
</programlisting>
<para>The XML Schema data type of a typed string O represented as 2 bytes in the O varchar value. This table maps this into the broader IRI space where the type URI is given an IRI number.</para>
<programlisting>
create table DB.DBA.RDF_LANGUAGE (
    RL_ID varchar not null primary key,
    RL_TWOBYTE integer not null unique );
</programlisting>
<para>The varchar representation of a O which is a string with language has a two byte field for language. This table maps the short integer language id to the real language name such as 'en', 'en-US' or 'x-any'.</para>
<para><emphasis>Note that unlike datatype names, language names are not URIs.</emphasis></para>
<para>A short integer value can be used in both RDF_DATATYPE and RDF_LANGUAGE tables for two different purposes. E.g. an integer 257 is for 'unspecified datatype' as well as for 'unspecified language'.</para>
</sect2>
<sect2 id="rdfsqlmodes"><title>Short, Long and SQL Values</title>
<para>When processing an O, the SPARQL implementation may have it in one of three internal formats, called "valmodes". The below cases apply for strings:</para>
<para>The short format is the format where an O is stored in RDF_QUAD.</para>
<para>The long value is an rdf_box object, that consists of six fields:</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>short integer id of type referencing RDT_TWOBYTE, 257   if the type is not specified,</listitem>
<listitem>the string as inlined in O or as stored in RO_VAL or   RO_LONG,</listitem>
<listitem>the RO_ID if the string is from RDF_OBJ (otherwise   zero),</listitem>
<listitem>the short integer id of language referencing RL_TWOBYTE, 257 if the language is not specified,</listitem>
<listitem>flag whether the stored string value is complete or it is only the beginning that is inlined in O.</listitem>
</itemizedlist>
<para>The SQL value is the string as a narrow string representing the UTF8 encoding of the value, stripped of data type and language tag.</para>
<para>The SQL form of an IRI is the string. The long and short forms are the IRI_ID referencing RU_IRI_ID of RDF_URL.</para>
<para>For all non-string, non-IRI types, the short, long and SQL values are the same SQL scalar of the appropriate native SQL type. A SQL host variable meant to receive an O should be of the ANY type.</para>
<para>The SPARQL implementation will usually translate results to the SQL format before returning them.
Internally, it uses the shortest possible form suited to the operation. For equalities and joining, the
short form is always good. For range comparisons, the long form is needed etc. For arithmetic,
all three forms will do since the arguments are expected to be numbers which are stored as their binary
selves in O, thus the O column unaltered and uncast will do as an argument of arithmetic or numeric
comparison with, say, SQL literal constants.</para>
</sect2>
<sect2 id="rdfxmlschemacompat"><title>Special Cases and XML Schema Compatibility</title>
<para>We note that since we store numbers as the equivalent SQL binary type, we do not preserve the distinction of byte, boolean etc. These all become integer. If preserving such detail is for some reason important, then storage as a typed string is possible but is not done at present for reasons of compactness and performance.</para>
</sect2>
<sect2 id="rdfquietcast"><title>SQL Compiler Support - QUIETCAST option</title>
<para>The type cast behaviors of SQL and SPARQL are different. SQL will generally signal an error when an automatic cast fails. For example, a string can be compared to a date column if the string can be parsed as a date but otherwise the comparison should signal an error. In SPARQL, such situations are supposed to silently fail. Generally, SPARQL is much more relaxed with respect to data types.</para>
<para>These differences will be specially noticed if actual SQL data is processed with SPARQL via some sort of schema mapping translating references to triples into native tables and columns.</para>
<para>Also, even when dealing with the triple-oriented RDF_QUAD table, there are cases of joining between S and O such that the O can be a heterogeneous set of IRI's and other data whereas the S is always an IRI. The non-IRI to IRI comparison should not give cast errors but should silently fail. Also, in order to keep queries simple and easily optimizable, it should not be necessary to introduce extra predicates for testing if the O is n IRI before comparing with the S.</para>
<para>Due to these considerations, Virtuoso introduces a SQL statement option called QUIETCAST. When given in the OPTION clause of a SELECT, it switches to silent fail mode for automatic type casting.</para>
<para>The syntax is as follows:</para>
<programlisting>
select ... from .... option (QUIETCAST)
</programlisting>
<para>This option is automatically added by the SPARQL to SQL translator. The scope is the enclosing procedure body.</para>
</sect2>
</sect1><sect1 id="rdfapiandsql">
<title>RDF and SPARQL API and SQL</title> 
<para>
SPARQL can be used inline wherever SQL can be used.  
The only API functions that one needs to know are the ones for loading RDF data into the store.
Dynamic SQL client applications can issue SPARQL queries against Virtuoso through the regular SQL client API, ODBC, JDBC or other, simply by prefixing the SPARQL query with the SPARQL keyword.  Parameters work just as with dynamic SQL.
Stored procedures can have SPARQL expressions inline and can declare cursors over SPARQL result sets.
</para>

<para>
Value conversions between SQL and SPARQL are most often automatic and
invisible.  In some cases one needs to be aware of the different
SPARQL value representations (valmodes). SPARQL offers declarations
for determining if graphs to be returned are to be represented as XML
or Turtle text serialization or whether these will be hash tables of
triples. See <link linkend="fn_dict_new"><function>dict_new()</function></link> and related functions for a description of the hash table SQL data type.
The use of dict's is convenient for further programmatic processing of graphs.
</para>

<para>RDF-related procedures use Virtuoso/PL vectors
and dictionaries to represent RDF triples and sets of triples.</para>
<para><emphasis>Valmode</emphasis> means the "format of values returned by an
expression", i.e. 'short', 'long' or 'SQL value'.</para>
<para><emphasis>Triple vector</emphasis> is a vector (array) of S, P and O, where all values are in
'long' formats, i.e. IRI_ID's for IRI values, numbers or datetimes for corresponding XMLSchema types, special &quot;RDF box&quot; objects if O is neither string nor IRI.</para>
<para><emphasis>Dictionary of triples</emphasis> or <emphasis>Hash table of triples</emphasis> is an
dictionary object made by the SQL function <emphasis>dict_new ()</emphasis> whose keys are
triple vectors and values are not specified; this is a good storage
format for an unordered set of distinct triples.</para>
<para><emphasis>Dictionary of blank node names</emphasis> is a dictionary used for tricky
processing of a number of TURTLE or RDF /XML descriptions of subgraphs
that come from a common graph. Imagine a situation where  different
descriptions actually refer to the same blank nodes of the original graph
and, moreover, the application that generates these descriptions always
generates the same blank node id string for the same node. A reader of
descriptions can correctly  join described subgraphs into one big
subgraph by filling in a dictionary that contains blank node id strings
as keys and IRI_ID's assigned to that strings as dependant data. As
soon as all readers of an application share the same dictionary of
nodes created before, no blank node is created twice;</para>

<sect2 id="rdfsparqlinline"><title>SPARQL Inline in SQL</title>
<para>Virtuoso extends the SQL 92 syntax with SPARQL queries and subqueries. Instead of writing a SQL SELECT query or subquery, one can write the SPARQL keyword and a SPARQL query after the keyword.</para>
<programlisting>
SQL>sparql select distinct ?p where { graph ?g { ?s ?p ?o } };
p
varchar
----------
http://example.org/ns#b
http://example.org/ns#d
http://xmlns.com/foaf/0.1/name
http://xmlns.com/foaf/0.1/mbox
...


SQL>select distinct subseq ("p", strchr ("p", '#')) as fragment
  from (sparql select distinct ?p where { graph ?g { ?s ?p ?o } } ) as all_predicates
  where "p" like '%#%';
fragment
varchar
----------
#query
#data
#name
#comment
...
</programlisting>
<para>Note that names of variables returned from SPARQL are always case-sensitive and no case mode rules apply to them.
Depending on CaseMode parameter in the virtuoso configuration file, double quotes should be used to refer to them in surrounding SQL code.
</para>
<para>
It is possible to pass parameters to a  SPARQL query via a Virtuoso-specific syntax extension.
<emphasis>??</emphasis> or <emphasis>$?</emphasis> indicates a positional parameter similar to <emphasis>?</emphasis> in plain SQL. <emphasis>??</emphasis> can be used in graph patterns or anywhere in the place of a SPARQL variable.
The value of a parameter should be passed in SQL form, i.e. this should be a number or a untyped string.
An IRI ID can be passed in all cases where an absolute IRI can, except the obvious case when the variable is an argument of a function that requires string.
If the parameter is used in 'graph', 'subject' or 'object' position of the sparql pattern, the string parameter is converted into IRI automatically.
In other cases, IRI string is undistinguishable from string literal, so there is a need in call of <emphasis>iri()</emphasis> built-in SPARL function, like <emphasis>iri (??)</emphasis>.
Using this notation, any dynamic SQL client, whether ODBC, JDBC or other can execute parameterized SPARQL queries, binding parameteres just as with dynamic SQL.
</para>
<programlisting><![CDATA[
SQL> create function param_passing_demo ()
{
  declare stat, msg varchar;
  declare mdata, rset any;
  exec ('sparql select ?s where { graph ?g { ?s ?? ?? }}',
    stat, msg,
    vector ( /* Vector of two parameters */
      'http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#int1',
      4 ),
    10, /* Max no of rows */
    mdata, /* Variable to get metadata */
    rset ); /* Variable to get result-set */
  if (length (rset) = 0)
    signal ('23000',
      'No data found, try demo database with installed Virtuoso tutorials');
  return rset[0][0];
}

SQL> select param_passing_demo ();
callret
VARCHAR
_______________________________________________________________________________

http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#four

1 Rows. -- 00000 msec.
]]></programlisting>
<para>An inline  SPARQL query can refer to SQL variables that are in scope in the SQL query or stored procedure containing it.
Virtuoso extends the SPARQL syntax with a special notation to this effect. A reference to SQL variable X can be written as <emphasis>?:X</emphasis> or <emphasis>$:X</emphasis>.
A reference to column <emphasis>C</emphasis> of table or sub-select with alias <emphasis>T</emphasis> can be written as <emphasis>?:T.C</emphasis> or <emphasis>$:T.C</emphasis>.
Both notations can be used in any place where a variable name is allowed, except 'AS' clause described below.
</para>
<para>A column of a result set of a SPARQL SELECT can be used in SQL code inside a for statement just like any column from a SQL select.
</para>
<para>SQL rules about double-quoted names are applicable to variables that are passed to a SPARQL query or selected  from one.
If a variable name contains unusual characters or should not be normalized according to SQL conventions then the
name should use double quotes for escaping. E.g., the notation <emphasis>?:"OrderLine"</emphasis> will always refer to variable or column
titled <emphasis>OrderLine</emphasis> whereas <emphasis>?:OrderLine</emphasis> can be converted to <emphasis>ORDERLINE</emphasis> or <emphasis>orderline</emphasis>.
</para>
<para>It is safer to avoid using variable names that conflict with column names of RDF system tables, esp. <emphasis>G</emphasis>, <emphasis>S</emphasis>, <emphasis>P</emphasis> and <emphasis>O</emphasis>.
These names are not reserved now but they may cause subtle bugs when an incorrect SPARQL subquery is compiled into SQL code that refers to table columns of same names.
Some of these names may be rejected as syntax errors by future Virtuoso versions.
</para>
<programlisting><![CDATA[
SQL> create procedure sql_vars_demo ()
{
#pragma prefix sort0: <http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#>
  declare RES varchar;
  declare obj integer;
  result_names (RES);
  obj := 4;
  for (sparql select ?subj where { graph ?g { ?subj sort0:int1 ?:obj } } ) do
    result ("subj");
}

SQL> sql_vars_demo ();
RES
VARCHAR
_______________________________________________________________________________

http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#four

1 Rows. -- 00000 msec.
]]></programlisting>
<para>The example also demonstrates the Virtuoso/PL pragma line for procedure-wide declarations of namespace prefixes.
This makes the code more readable and eliminates duplicate declarations of namespace prefixes when the procedure
contains many SPARQL fragments that refer to a common set of namespaces.
</para>
<para>SPARQL ASK query can be used as an argument of the SQL EXISTS predicate.
</para>
<programlisting><![CDATA[
create function sparql_ask_demo () returns varchar
{
  if (exists (sparql ask where { graph ?g { ?s ?p 4}}))
    return 'YES';
  else
    return 'NO';
}

SQL> select sparql_ask_demo ();
_______________________________________________________________________________

YES
]]>
</programlisting>
<sect3 id="rdfcontrollingsparqloutputtypes"><title>Controlling SPARQL Output Data Types</title>
<para>The compilation of a SPARQL query may depend on environment that is usually provided by the SPARQL protocol, including name of default graph URI. Environment settings that come from protocol may override settings in the text of SPARQL query. To let an application configure the environment for a query,
 SPARQL syntax is extended with the 'define' clause:</para>
<programlisting>
define parameter-qname parameter-value
</programlisting>
<para>Examples of supported parameters are <emphasis>output:valmode</emphasis> and <emphasis>output:format</emphasis></para>
<para><emphasis>output:valmode</emphasis> sets the SQL representation used for values in the result set.
In most cases applications need SQL values to be returned by SPARQL.
By default the query returns a result set of values in SQL format and behaves as a typical SQL select.
To compose triple vectors in Virtuoso/PL code application may need data in long format.
If the query contains a</para>
<programlisting>
define output:valmode 'LONG'
</programlisting>
<para>clause then all returned values are in long format. E.g., the following query returns IRI_ID's instead of IRI strings.</para>
<programlisting>
SQL>sparql define output:valmode 'LONG' select distinct ?p where { graph ?g { ?s ?p ?o } };
p
----------
#i1000001
#i1000003
#i1000005
#i1000006
...
</programlisting>
<para><emphasis>output:format</emphasis> instruct SPARQL compiler that the result of the query should be serialized into an RDF document;
that document will be returned as  a single column  of a single  row result set.
<emphasis>output:format</emphasis> is especially useful if SPARQL CONSTRUCT or SPARQL DESCRIBE query is executed directly via ODBC or JDBC database connection
and the client can not receive the resulting dictionary of triples (there's no way to transfer such an object via ODBC).
Using this option, the  client can receive the document that contains the whole result set of a SELECT or the dictionary of triples of a CONSTRUCT/DESCRIBE, and parse it locally.
</para>
<para>
Supported values for <emphasis>output:format</emphasis> are <emphasis>RDF/XML</emphasis> and <emphasis>TURTLE</emphasis> (or <emphasis>TTL</emphasis>).
If both <emphasis>output:valmode</emphasis> and <emphasis>output:format</emphasis> are specified, <emphasis>output:format</emphasis> has higher priority,
raising an error if <emphasis>output:valmode</emphasis> is set to a value other than <emphasis>LONG</emphasis>.
</para>
<para>
When a SPARQL query is compiled, the compiler checks whether the result set is sent to the remote ODBC/JDBC client or used in some other way.
The compiler will automatically set <emphasis>output:format</emphasis> to <emphasis>TURTLE</emphasis> if compiling for execution by an SQL client.
</para>
<para>
The example below demonstrates how different values of <emphasis>output:format</emphasis> affect the result of SPARQL SELECT.
Note 10 rows and 4 columns in the first result, and single LONG VARCHAR in two others.
Using the ISQL  client, use 'set blobs on;' directive to fetch long texts without 'data truncated' warning.
</para>
<programlisting><![CDATA[
SQL> sparql select * where {graph ?g { ?s ?p ?o }} limit 10;
g                                            s                    p                              o
VARCHAR                                      VARCHAR              VARCHAR                        VARCHAR
______________________________________________________________________

http://local.virt/DAV/bound/manifest.rdf     nodeID://1000000000  http://example.com/test#query  http://local.virt/DAV/bound/bound1.rq
. . .
http://local.virt/DAV/examples/manifest.rdf  nodeID://1000000019  http://example.com/test#query  http://local.virt/DAV/examples/ex11.2.3.1_1.rq

10 Rows. -- 00000 msec.

SQL> sparql define output:format "TTL" select * where {graph ?g { ?s ?p ?o }} limit 10;
callret-0
LONG VARCHAR
_______________________________________________________________________________

@prefix :rdf <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
 @prefix :rs <http://www.w3.org/2005/sparql-results#> .
 @prefix :xsd <http://www.w3.org/2001/XMLSchema#> .
 [ rdf:type rs:results ;
  rs:result [
      rs:binding [ rs:name "g" ; rs:value <http://local.virt/DAV/bound/manifest.rdf> ] ;
      rs:binding [ rs:name "s" ; rs:value _:nodeID1000000000 ] ;
      rs:binding [ rs:name "p" ; rs:value <http://example.com/test#query> ] ;
      rs:binding [ rs:name "o" ; rs:value <http://local.virt/DAV/bound/bound1.rq> ] ;
      ] ;

. . .

  rs:result [
      rs:binding [ rs:name "g" ; rs:value <http://local.virt/DAV/examples/manifest.rdf> ] ;
      rs:binding [ rs:name "s" ; rs:value _:nodeID1000000019 ] ;
      rs:binding [ rs:name "p" ; rs:value <http://example.com/test#query> ] ;
      rs:binding [ rs:name "o" ; rs:value <http://local.virt/DAV/examples/ex11.2.3.1_1.rq> ] ;
      ] ;
    ] .

1 Rows. -- 00000 msec.

SQL> sparql define output:format "RDF/XML" select * where {graph ?g { ?s ?p ?o }} limit 10;
callret-0
LONG VARCHAR
_______________________________________________________________________________

<rdf:RDF
  xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
  xmlns:rs="http://www.w3.org/2005/sparql-results#"
  xmlns:xsd="http://www.w3.org/2001/XMLSchema#" >
   <rs:results rdf:nodeID="rset">
  <rs:result rdf:nodeID="sol206">
   <rs:binding rdf:nodeID="sol206-0" rs:name="g"><rs:value rdf:resource="http://local.virt/DAV/bound/manifest.rdf"/></rs:binding>
   <rs:binding rdf:nodeID="sol206-1" rs:name="s"><rs:value rdf:nodeID="1000000000"/></rs:binding>
   <rs:binding rdf:nodeID="sol206-2" rs:name="p"><rs:value rdf:resource="http://example.com/test#query"/></rs:binding>
   <rs:binding rdf:nodeID="sol206-3" rs:name="o"><rs:value rdf:resource="http://local.virt/DAV/bound/bound1.rq"/></rs:binding>
  </rs:result>

. . .

  <rs:result rdf:nodeID="sol5737">
   <rs:binding rdf:nodeID="sol5737-0" rs:name="g"><rs:value rdf:resource="http://local.virt/DAV/examples/manifest.rdf"/></rs:binding>
   <rs:binding rdf:nodeID="sol5737-1" rs:name="s"><rs:value rdf:nodeID="1000000019"/></rs:binding>
   <rs:binding rdf:nodeID="sol5737-2" rs:name="p"><rs:value rdf:resource="http://example.com/test#query"/></rs:binding>
   <rs:binding rdf:nodeID="sol5737-3" rs:name="o"><rs:value rdf:resource="http://local.virt/DAV/examples/ex11.2.3.1_1.rq"/></rs:binding>
  </rs:result>
 </rs:results>
</rdf:RDF>

1 Rows. -- 00000 msec. 
]]></programlisting>
<para>SPARQL CONSTRUCT and SPARQL DESCRIBE results are serialized as one would expect:</para>
<programlisting><![CDATA[
SQL> sparql define output:format "TTL" construct { ?s ?p "004" } where {graph ?g { ?s ?p 4 }};
callret-0
LONG VARCHAR
_______________________________________________________________________________

<http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#four> <http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#int1> "004" .
_:b1000000913 <http://www.w3.org/2001/sw/DataAccess/tests/result-set#index> "004" .


1 Rows. -- 00000 msec.

SQL> sparql define output:format "RDF/XML" construct { ?s ?p "004" } where {graph ?g { ?s ?p 4 }};
callret-0
LONG VARCHAR
_______________________________________________________________________________

<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
<rdf:Description about="http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#four"><ns0pred:int1 xmlns:ns0pred="http://www.w3.org/2001/sw/DataAccess/tests/data/Sorting/sort-0#">004</ns0pred:int1></rdf:Description>
<rdf:Description rdf:nodeID="b1000000913"><ns0pred:index xmlns:ns0pred="http://www.w3.org/2001/sw/DataAccess/tests/result-set#">004</ns0pred:index></rdf:Description>
</rdf:RDF>

1 Rows. -- 00000 msec. 
]]></programlisting>
<para>SPARQL ASK returns a non-empty result set if the match is found for graph pattern, empty result-set otherwise. If <emphasis>output:format</emphasis> is specified then the query makes a 'boolean result' document instead:</para>
<programlisting><![CDATA[
SQL> sparql ask where {graph ?g { ?s ?p 4 }};
__ask_retval
INTEGER
_______________________________________________________________________________

1

1 Rows. -- 00000 msec.

SQL> sparql ask where {graph ?g { ?s ?p "no such" }};
__ask_retval
INTEGER
_______________________________________________________________________________


0 Rows. -- 00000 msec.

SQL> sparql define output:format "TTL" ask where {graph ?g { ?s ?p 4 }};
callret
VARCHAR
_______________________________________________________________________________

@prefix :rdf <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
 @prefix :rs <http://www.w3.org/2005/sparql-results#> .
[ rdf:type rs:results ; rs:boolean TRUE ]

1 Rows. -- 00000 msec.

SQL> sparql define output:format "RDF/XML" ask where {graph ?g { ?s ?p 4 }};
callret
VARCHAR
_______________________________________________________________________________

<rdf:RDF
  xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
  xmlns:rs="http://www.w3.org/2005/sparql-results#"
  xmlns:xsd="http://www.w3.org/2001/XMLSchema#" >
   <rs:results rdf:nodeID="rset">
    <rs:boolean rdf:datatype="http://www.w3.org/2001/XMLSchema#boolean">1</rs:boolean></results></rdf:RDF>

1 Rows. -- 00000 msec.
]]></programlisting>
</sect3>
</sect2>



<sect2 id="rdfapi">
<title>API Functions</title> 

<sect3
id="rdfapidataimport"><title>Data Import</title>
<para>DB.DBA.TTLP() parses TTL (TURTLE or N3 resource) and places its triples into DB.DBA.RDF_QUAD.</para>
<programlisting>
create procedure DB.DBA.TTLP (
    in strg any,       -- text of the resource
    in base varchar,  -- base IRI to resolve relative IRIs to absolute
    in graph varchar, -- target graph IRI, parsed triples will appear in that graph.
    in flags int)   -- bitmask of flags that permit some sorts of syntax errors in resource, use 0.
</programlisting>
<para>For loading a file of any greater length, it is most practical to use
the file_to_string_output function.
</para>
<para>It is important the file to be accessible for the Virtuoso server. You need to have set properly the
<emphasis>DirsAllowed</emphasis> parameter value in section [Parameters] of the Virtuoso database INI file.
For example on Windows it could be:
</para>
<programlisting>
virtuoso.ini file:
[Parameters]
...
DirsAllowed =  .\tmp
...
</programlisting>
<para>So in the example the file you want to import from, should be in the tmp folder or in its subfolder.
Note that this example folder is a subfolder of the Virtuoso Server working directory.
</para>
<programlisting>
SQL> ttlp (file_to_string_output ('.\tmp\data.ttl'), '', 'http://my_graph', 0);
</programlisting>
<para>The DB.DBA.TTLP_MT() procedure is like DB.DBA.TTLP() but loads the file on multiple threads,
using parallel IO and multiprocessing if available. The functions does not leave a transaction log.
Hence, after successful load, one should execute the checkpoint statement to make sure that a
server restart does not wipe out the results.
</para>
<programlisting>
create procedure DB.DBA.TTLP_MT (
    in strg any,       -- text of the resource
    in base varchar,   -- base IRI to resolve relative IRIs to absolute
    in graph varchar,  -- target graph IRI, parsed triples will appear in that graph.
    in flags int) -- flags, use 0
</programlisting>
<para>The DB.DBA.RDF_TTL2HASH() does not load TTL content, instead it returns a dict of triples in 'long valmode'.</para>
<programlisting>
create function DB.DBA.RDF_TTL2HASH (
    in strg any,
    in base varchar,
    in graph varchar ) returns any
</programlisting>
<para>Parameter <emphasis>flags</emphasis> is useful when syntax of resource is TURTLE-like but not correct TURTLE.
By default, use zero value.
Add 1 to let string literals contain end-of-line characters.
Add 2 to suppress error messages on blank node verbs.
Add 4 to let variables instead of blank nodes.
Add 8 to silently skip triples with literal subjects.
</para>
<para>The DB.DBA.RDF_LOAD_RDFXML() procedure parses RDF/XML and places its triples into DB.DBA.RDF_QUAD.</para>
<programlisting>
create procedure DB.DBA.RDF_LOAD_RDFXML (
    in strg any,           -- text of and XML document
    in base_iri varchar,   -- base IRI to resolve relative IRIs
    in graph_iri varchar ) -- the IRI of destination graph
</programlisting>
<para>To insert a single quad into DB.DBA.RDF_QUAD() table, use one of these procedures:</para>
<programlisting>
-- Simple insertion of a quad where object is a node
create procedure DB.DBA.RDF_QUAD_URI (
  in g_uri varchar, in s_uri varchar, in p_uri varchar,
  in o_uri varchar ) -- IRI string or IRI_ID

-- Simple insertion of a quad where object is a literal value in 'SQL valmode'
create procedure DB.DBA.RDF_QUAD_URI_L (
  in g_uri varchar, in s_uri varchar, in p_uri varchar,
  in o_lit any ) -- string, number or datetime, NULL is not allowed

create procedure DB.DBA.RDF_QUAD_URI_L_TYPED (
  in g_uri varchar, in s_uri varchar, in p_uri varchar,
  in o_lit any,     -- string value of the literal
  in dt any,        -- datatype as IRI string or IRI_ID, can be NULL
  in lang varchar ) -- language as string or NULL
</programlisting>
<para>Arguments g_uri, s_uri and p_uri of these three functions should be IRI strings or IRI_IDs.
All string arguments should be in UTF-8 encoding, otherwise they will be stored but are not queriable via SPARQL.</para>
</sect3>
<sect3 id="rdfapidataexport"><title>Data Export</title>
<para>These two procedures serializes vector of triples into a session, in TURTLE or RDF/XML syntax.
In current version, every triple is printed in separate top-level record (say, in rdf:Description tag), without any pretty-print or nesting optimization.
</para>
<programlisting>
create procedure DB.DBA.RDF_TRIPLES_TO_TTL (
    inout triples any, -- vector of triples in 'long valmode'.
    inout ses any )    -- an output stream in server default encoding

create procedure DB.DBA.RDF_TRIPLES_TO_RDF_XML_TEXT (
    inout triples any,          -- vector of triples in 'long valmode'.
    in print_top_level integer, -- zero if only rdf:Description tags should be written,
      -- non-zero if the rdf:RDF top-level element should also be written
    inout ses any )             -- an output stream in server default encoding
</programlisting>
</sect3>
<sect3 id="rdfapidataquery"><title>Data query</title>
<programlisting>
-- Local execution of SPARQL via SPARQL protocol, produces a result set of SQL values.
create procedure DB.DBA.SPARQL_EVAL (
    in query varchar,      -- text of SPARQL query to execute
    in dflt_graph varchar, -- default graph IRI, if not NULL then this overrides what's specified in query
    in maxrows integer )   -- limit on numbers of rows that should be returned.

-- Similar to SPARQL_EVAL, but returns a vector of vectors of SQL values.
create function DB.DBA.SPARQL_EVAL_TO_ARRAY (
    in query varchar,      -- text of SPARQL query to execute
    in dflt_graph varchar, -- text of SPARQL query to execute
    in maxrows integer )   -- limit on numbers of rows that should be returned.
returns any
</programlisting>
<programlisting>
-- Remote execution of SPARQL via SPARQL protocol, produces a result set of SQL values.
create procedure DB.DBA.SPARQL_REXEC (
    in service varchar,    -- service URI to call via HTTP
    in query varchar,      -- text of SPARQL query to execute
    in dflt_graph varchar, -- default graph IRI, if not NULL then this overrides what's specified in query
    in named_graphs any,   -- vector of named graph IRIs, if not NULL then this overrides what's specified in query
    in req_hdr any,        -- additional HTTP header lines that should be passed to the service; 'Host: ...' is most popular.
    in maxrows integer,    -- limit on numbers of rows that should be returned.
    in bnode_dict any )    -- dictionary of bnode ID references.

-- Similar to SPARQL_REXEC (), but returns a vector of vectors of SQL values.
-- All arguments are the same.
create function DB.DBA.SPARQL_REXEC_TO_ARRAY (
    in service varchar, in query varchar, in dflt_graph varchar, in named_graphs any,
    in req_hdr any, in maxrows integer, in bnode_dict any)
returns any

-- Similar to SPARQL_REXEC (), but fills in output parameters with metadata (like exec metadata) and a vector of vector
s of 'long valmode' values.
-- First seven arguments are the same.
create procedure DB.DBA.SPARQL_REXEC_WITH_META (
    in service varchar, in query varchar, in dflt_graph varchar, in named_graphs any,
    in req_hdr any, in maxrows integer, in bnode_dict any,
    out metadata any,  -- metadata like exec () returns.
    out resultset any) -- results as 'long valmode' value.
</programlisting>
<para>If the query is a CONSTRUCT or DESCRIBE then the result set consists of a single row and single column, the value inside is a dict of triples in 'long valmode'.</para>
</sect3>
</sect2>
<sect2 id="rdfinternalfunctions"><title>Useful Internal Functions</title>
<sect3 id="rdfinternalconversion"><title>Conversion Functions for XMLSchema/RDF Data Serialization Syntax</title>
<para>These functions emulate constructor functions from XQuery Core Function Library.</para>
<programlisting>
create function DB.DBA."http://www.w3.org/2001/XMLSchema#boolean" (in strg any) returns integer
create function DB.DBA."http://www.w3.org/2001/XMLSchema#dateTime" (in strg any) returns datetime
create function DB.DBA."http://www.w3.org/2001/XMLSchema#double" (in strg varchar) returns double precision
create function DB.DBA."http://www.w3.org/2001/XMLSchema#float" (in strg varchar) returns float
create function DB.DBA."http://www.w3.org/2001/XMLSchema#integer" (in strg varchar) returns integer
</programlisting>
</sect3>
<sect3 id="rdfinternalpredicates"><title>RDF-specific Predicates</title>
<programlisting>
-- Returns 1 if string s matches pattern p, 0 otherwise
create function DB.DBA.RDF_REGEX (
    in s varchar,            -- source string to check
    in p varchar,            -- regular expression pattern string
    in coll varchar := null) -- unused for now (modes are not yet implemented)

-- Returns 1 if language identifier r matches lang pattern t
create function DB.DBA.RDF_LANGMATCHES (
  in r varchar, -- language identifies (string or NULL)
  in t varchar) -- language pattern (exact name, first two letters or '*')
</programlisting>
</sect3>
</sect2>
<sect2 id="rdfdefaultgraph"><title>Default and Named Graphs</title>
<para>Sometimes the default graph IRI is not known when the SPARQL query is composed. It can be added at the very last moment by providing the IRI in 'define' clause as follows:</para>
<programlisting>
define input:default-graph-uri &lt;http://example.com&gt;
</programlisting>
<para>Such a definition overrides the default graph URI set in query by 'FROM ...' clause (if any).</para>
<para>The query may contain more than one <emphasis>define input:default-graph-uri</emphasis>.
The set of values of <emphasis>input:default-graph-uri</emphasis> has the highest possible priority and can not be redefined in the rest of the text of the query by FROM clauses.</para>
<para>Similarly, <emphasis>define input:named-graph-uri &lt;http://example.com&gt;</emphasis> is a replacement for FROM NAMED clause</para>
<para>
When Virtuoso receives a SPARQL request via HTTP, the value of default graph can be set in protocol as <emphasis>default-graph-uri</emphasis> HTTP parameter.
Multiple occurencies of this parameter are allowed. This HTTP parameter is converted into <emphasis>define input:default-graph-uri</emphasis>.
There's similar support for <emphasis>named-graph-uri</emphasis> HTTP parameter.
For debugging purposes, graph names set in protocol are sent back in the reply header as <emphasis>X-SPARQL-default-graph: ...</emphasis> and <emphasis>X-SPARQL-named-graph: ...</emphasis> header lines, one line per graph.
</para>
<para>
Web service endpoint may provide different default configurations for different host names mentioned in HTTP request.
This is configured via table <emphasis>DB.DBA.SYS_SPARQL_HOST</emphasis>.
</para>
<programlisting>
create table DB.DBA.SYS_SPARQL_HOST (
  SH_HOST	varchar not null primary key, -- host mask
  SH_GRAPH_URI	varchar,      -- 'default default' graph uri
  SH_USER_URI	varchar,      -- reserved for any use in applications
  SH_DEFINES	long varchar  -- additional defines for requests
)
</programlisting>
<para>
When the SPARQL web service endpoint receives a request it checks the <emphasis>Host</emphasis> HTTP header line.
This line contains zero or more target host names, delimited by commas.
For every host name in the line the service scans the <emphasis>DB.DBA.SYS_SPARQL_HOST</emphasis> in search of row such that host name is like <emphasis>SH_HOST</emphasis>.
The <emphasis>SH_HOST</emphasis> acts as 'pattern' argument for SQL string operator LIKE. If the row is found then the text of SPARQL request is extended.
If default graph is not explicitly set by HTTP parameters and <emphasis>SH_GRAPH_URI</emphasis> is not null then default graph is set to <emphasis>SH_GRAPH_URI</emphasis>.
If <emphasis>SH_DEFINES</emphasis> is not null then it is added in front of query so this field is a good place for text for any <emphasis>define</emphasis> options.
</para>
<para>
The search in <emphasis>DB.DBA.SYS_SPARQL_HOST</emphasis> stops at the first found row, other possible matches are silently ignored.
</para>
</sect2>
<sect2 id="rdfsqlfromsparql"><title>Calling SQL from SPARQL </title>
<para>A SPARQL expression can contain calls of Virtuoso/PL functions
and built-in SQL functions in both the WHERE clause and in
result set. Two namespace prefixes, <emphasis>bif</emphasis> and <emphasis>sql</emphasis> are reserved for
these purposes. When a function name starts with <emphasis>bif:</emphasis> namespace
prefix, the rest of name is treated as a name of SQL BIF (Built-In
Function). When a function name starts with <emphasis>sql:</emphasis> namespace prefix,
the rest of name is treated as a name of Virtuoso/PL function owned by
DBA with database qualifier DB, e.g. <emphasis>sql:example(...)</emphasis> is
converted into <emphasis>DB.DBA."example"(...)</emphasis>.</para>

<para>In both cases,
the function receives arguments in SQL format ('SQL valmode') and
returns the result also in SQL format.  The SPARQL compiler will
automatically add code for format conversion into the resulting SQL
code so SQL functions can be used even if <emphasis>define output:valmode
'LONG'</emphasis> forces the use of internal RDF representation in the
result set.</para>
</sect2>
</sect1>
   <sect1 id="rdfsparul"><title>SPARUL -- an Update Language For RDF Graphs</title>
     <sect2 id="rdfsparulintro"><title>Introduction</title>
       <para>Starting from version 5.0, Virtuoso supports
<ulink url="http://jena.hpl.hp.com/~afs/SPARQL-Update.html">SPARQL/Update</ulink> extension of SPARQL.
This is sufficient for most of routine data manipulation operations. If <emphasis>SPARQL_UPDATE</emphasis>
role is granted to <emphasis>SPARQL</emphasis> user then data manipulation statements may be
executed via SPARQL web service endpoint as well as data querying.
       </para>
     </sect2>
     <sect2 id="rdfsparulfunc"><title>Manage RDF Storage</title>
       <para>Two functions allow the user to alter RDF storage by inserting or deleting all
triples listed in some vector. Both functions receive an IRI of a graph that should be altered and
a vector of triples that should be added or removed. The graph IRI can be either IRI ID or a string.
The third optional argument of these functions control transactional behaviour: the value of parameter is
passed to <link linkend="fn_log_enable"><function>log_enable</function></link> function.
The return values of functions are not defined and should not be used by applications.
       </para>
       <programlisting>
create function DB.DBA.RDF_INSERT_TRIPLES (in graph_iri any, in triples any, in log_mode integer := null)
create function DB.DBA.RDF_DELETE_TRIPLES (in graph_iri any, in triples any, in log_mode integer := null)
       </programlisting>
       <para>Simple operations may be faster if written as low-level SQL code instead of using SPARUL.
E.g, the use of SPARQL DELETE is redundant when the application should delete from RDF_QUAD
by using simple filters like:
       </para>
       <programlisting>
delete from DB.DBA.RDF_QUAD
where G = DB.DBA.RDF_MAKE_IID_OF_QNAME (
    'http://local.virt/DAV/sparql_demo/data/data-xml/source-simple2/source-data-01.rdf' );
       </programlisting>
       <para>On the other hand, simple filters does not work when search criteria refer to triples
that are affected by the modification. Consider a function that deletes all triples whose subjects
are nodes of type 'http://xmlns.com/foaf/0.1/Person'. Type information is stored in triples that
will be deleted, so the simplest function is something like this:
       </para>
<programlisting><![CDATA[
create procedure DELETE_PERSONAL_DATA (in foaf_graph varchar)
{
  declare pdata_dict, pdata_array any;
-- Step 1: select everything that should be deleted
  pdata_dict := ((
      sparql construct { ?s ?p ?o }
      where { graph ?:foaf_graph {
              ?s ?p ?o . ?s rdf:type <http://xmlns.com/foaf/0.1/Person>
            } }
      ));
-- Step 2: delete all found triples
  pdata_array := dict_list_keys (pdata_dict, 1);
  RDF_DELETE_TRIPLES (foaf_graph, pdata_array);
};

DELETE_PERSONAL_DATA (
  'http://local.virt/DAV/sparql_demo/data/data-xml/source-simple2/source-data-01.rdf' );
]]></programlisting>
       <para>Starting from Virtuoso 5.0, application may use SPARUL to do the same in a convenient way:
       </para>
<programlisting><![CDATA[
create procedure DELETE_PERSONAL_DATA (in foaf_graph varchar)
{
  sparql delete { ?s ?p ?o }
      where { graph ?:foaf_graph {
              ?s ?p ?o . ?s rdf:type <http://xmlns.com/foaf/0.1/Person>
           } }
};
]]></programlisting>
     </sect2>
     <sect2 id="rdfsparulexamples"><title>Examples</title>
       <para>The graph where changes take place may be specified by an option in front of query, instead
of being specified in 'insert into graph' clause.
       </para>
<programlisting><![CDATA[
sparql define input:default-graph-uri <SparqlActions> insert { <s0> <p0> <o0> };
]]></programlisting>
       <para>The following two statements are equivalent but the latter may work faster, especially
if there are many RDF views in the system or if some RDF views may contain triples for the graph
in question. Note that neither of these two affect data that might come from RDF views.
       </para>
<programlisting><![CDATA[
sparql delete from graph <SparqlActions> { ?s ?p ?o } from <SparqlActions> where { ?s ?p ?o };
sparql clear graph <SparqlActions>;
]]></programlisting>
       <para>Keywords 'insert in' and 'insert into' are interchangeable in Virtuoso for backward
compatibility but SPARUL spec lists only 'insert into':
       </para>
<programlisting><![CDATA[
sparql insert in graph <SparqlActions> { <s1> <p11> <o111>, <o112> ; <p12> <o121> , <o122> };
sparql insert into graph <SparqlActions> { <s2> <p2> <o2> };
]]></programlisting>
       <para>It is possible to use various expressions to calculate fields of new triples. This is
proven to be very convenient, even if not a part of the original spec.
       </para>
<programlisting><![CDATA[
sparql insert into graph <SparqlActions> { `iri (bif:concat (str (?s), "new"))` <p11> ?o } where { ?s <p11> ?o };
]]></programlisting>
       <para>'Modify graph' may be used as a sort of 'update' operation.
       </para>
<programlisting><![CDATA[
sparql modify graph <SparqlActions> delete { ?s <p2> ?o } insert { ?s <p2new> ?o } where { ?s <p2> ?o };
sparql delete from graph <SparqlActions> { <s2> <p2new> <o2> };
]]></programlisting>
       <para>The resource URL can be calculated by a string expression.</para>
<programlisting><![CDATA[
sparql load bif:concat ("http://", bif:registry_get("URIQADefaultHost"), "/inputs/SparqlDawg/data-xml/Expr1/manifest.rdf")
   into graph <SparqlActions>;
]]></programlisting>
       <para>Number of operations can be sent to a web service endpoint as a single statement and
executed in sequence.
       </para>
<programlisting><![CDATA[
sparql
  insert in graph <SparqlActions> { <s1> <p11> <o111>, <o112> ; <p12> <o121> , <o122> }
  insert into graph <SparqlActions> { <s2> <p2> <o2> }
  insert into graph <SparqlActions> { `iri (bif:concat (str (?s), "new"))` <p11> ?o } where { ?s <p11> ?o }
  modify graph <SparqlActions> delete { ?s <p2> ?o } insert { ?s <p2new> ?o } where { ?s <p2> ?o }
  delete from graph <SparqlActions> { <s2> <p2new> <o2> }
  load bif:concat ("http://", bif:registry_get("URIQADefaultHost"), "/inputs/SparqlDawg/data-xml/Expr1/manifest.rdf") into graph <SparqlActions>
;
]]></programlisting>
      </sect2>
   </sect1>
<sect1 id="rdfiridereferencing"><title>Dereferencable IRIs and RDF Linked Data</title>
<para>There are many cases when RDF data should be retrieved from remote sources only when really needed.
E.g., a scheduling application may read personal calendars from personal sites of its users.
Calendar data expire quickly, so there's no reason to frequently re-load them in hope that they are queried before expired.
</para>
<para>
Virtuoso extends SPARQL so it is possible to download RDF resource from a given IRI, parse them and store the resulting triples in a graph, all three operations will be performed during the SPARQL query execution.
The IRI of graph to store triples is usually equal to the IRI where the resource is download from, so the feature is named &quot;IRI dereferencing&quot;
There are two different use cases for this feature.
In simple case, a SPARQL query contains <emphasis>from</emphasis> clauses that enumerate graphs to process, but there are no triples in <emphasis>DB.DBA.RDF_QUAD</emphasis> that correspond to some of these graphs.
The query execution starts with dereferencing of these graphs and the rest runs as usual.
In more sophisticated case, the query is executed many times in a loop.
Every execution produces a partial result.
SPARQL processor checks for IRIs in the result such that resources with that IRIs may contain relevant data but not yet loaded into the <emphasis>DB.DBA.RDF_QUAD</emphasis>.
After some iteration, the partial result is identical to the result of the previous iteration, because there's no more data to retrieve.
As the last step, SPARQL processor builds the final result set.
</para>
<sect2 id="rdfinputgrab"><title>IRI Dereferencing For FROM Clauses, &quot;define get:...&quot; Pragmas</title>
<para>Virtuoso extends SPARQL syntax of <emphasis>from</emphasis> and <emphasis>from named</emphasis> clauses.
It allows additional list of options at end of clause: <emphasis>option ( param1 value1, param2 value2, ... )</emphasis>
where parameter names are QNames that start with <emphasis>get:</emphasis> prefix and values are &quot;precode&quot; expressions, i.e. expressions that does not contain variables other than external parameters.
Names of allowed parameters are listed below.
</para>
<itemizedlist>
  <listitem><emphasis>get:soft</emphasis> is the retrieval mode, supported values are &quot;soft&quot; and &quot;replacing&quot;.
If the value is &quot;soft&quot; then the SPARQL processor will not even try to retrieve triples if the destination graph is non-empty.
Other <emphasis>get:...</emphasis> parameters are useless without this one.</listitem>
  <listitem><emphasis>get:uri</emphasis> is the IRI to retrieve if it is not equal to the IRI of the <emphasis>from</emphasis> clause.
These can be used if data should be retrieved from a mirror, not from original resource location or in any other case when the destination graph IRI differs from the location of the resource.</listitem>
  <listitem><emphasis>get:method</emphasis> is the HTTP method that should be used to retrieve the resource, supported methods are &quot;GET&quot; for plain HTTP and &quot;MGET&quot; for URIQA web service endpoint.
By default, &quot;MGET&quot; is used for IRIs that end with &quot;/&quot; and &quot;GET&quot; for everything else.</listitem>
  <listitem><emphasis>get:refresh</emphasis> is the maximum allowed age of the cached resource, no matter what is specified by the server where the resource resides.
The value is an positive integer (number of seconds). Virtuoso reads HTTP headers and uses &quot;Date&quot;, &quot;ETag&quot;, &quot;Expires&quot;, &quot;Last-Modified&quot;, &quot;Cache-Control&quot; and &quot;Pragma: no-cache&quot; fields to calculate when the resource should be reloaded, this value can become smaller due to <emphasis>get:refresh</emphasis> but can not be incremented.</listitem>
  <listitem><emphasis>get:proxy</emphasis> address of the proxy server, as &quot;host:port&quot; string, if direct download is impossible; the default is to not use proxy.</listitem>
<!--
  <listitem><emphasis>get:login</emphasis></listitem>
  <listitem><emphasis>get:password</emphasis></listitem>
  <listitem><emphasis>get:query</emphasis></listitem> -->
<para>If a value of some <emphasis>get:...</emphasis> parameter repeats for every <emphasis>from</emphasis> clause then it can be written as a global
pragma like <emphasis>define get:soft "soft"</emphasis>.
The following two queries will work identically:
</para>
<programlisting><![CDATA[
sparql
select ?id
from named <http://myhost/user1.ttl>
  option (get:soft "soft", get:method "GET")
from named <http://myhost/user2.ttl>
  option (get:soft "soft", get:method "GET")
where { graph ?g { ?id a ?o } };

sparql
define get:method "GET"
define get:soft "soft"
select ?id
from named <http://myhost/user1.ttl>
from named <http://myhost/user2.ttl>
where { graph ?g { ?id a ?o } };
]]></programlisting>
<para>
It can make text shorter and it is especially useful when the query text comes from client but the parameter should have a fixed value due to security reasons:
the values set by <emphasis>define get:...</emphasis> can not be redefined inside the query and the application may prevent the text with desired pragmas before the execution.
</para>
<para>
Note that the user should have <emphasis>SPARQL_UPDATE</emphasis> role in order to execute such a query.
By default SPARQL web service endpoint is owned by <emphasis>SPARQL</emphasis> user that have <emphasis>SPARQL_SELECT</emphasis> but not
<emphasis>SPARQL_UPDATE</emphasis>.
It is possible in principle to grant <emphasis>SPARQL_UPDATE</emphasis> to <emphasis>SPARQL</emphasis> but this breaches the whole security of the RDF storage.
</para>
</itemizedlist>
</sect2>
<sect2 id="rdfinputgrab"><title>IRI Dereferencing For Variables, &quot;define input:grab-...&quot; Pragmas</title>
<para>
Consider a set of personal data such that one resource can list many persons and point to resources where that persons are described in more details.
E.g. resource about <emphasis>user1</emphasis> describes the user and also contain statements that <emphasis>user2</emphasis> and <emphasis>user3</emphasis> are persons and more data can be found in <emphasis>user2.ttl</emphasis> and <emphasis>user3.ttl</emphasis>,
<emphasis>user3.ttl</emphasis> can contain statements that <emphasis>user4</emphasis> is also person and more data can be found in <emphasis>user4.ttl</emphasis> and so on.
The query should find as many users as it is possible and return their names and e-mails.
</para>
<para>
If all data about all users were loaded into the database, the query could be quite simple:
</para>
<programlisting><![CDATA[
sparql select ?id ?fullname ?email
where {
    graph ?g {
        ?id a <Person> ;
          <FullName> ?fullname ;
          <EMail> ?email .
      } };
]]></programlisting>
<para>
It is possible to enable IRI dereferencing in such a way that all appropriate resources are loaded during the query execution even if names of some of them are not known a priori.
</para>
<programlisting><![CDATA[
sparql
  define input:grab-var "?more"
  define input:grab-depth 10
  define input:grab-limit 100
  define input:grab-base-iri "http://myhost/"
select ?id ?fullname ?email
where {
    graph ?g {
        ?id a <Person> ;
          <FullName> ?fullname ;
          <EMail> ?email .
	optional { ?id <SeeAlso> ?more } } };
]]></programlisting>
<para>
The IRI dereferencing is controlled by the following pragmas:
</para>
<itemizedlist>
  <listitem><emphasis>input:grab-var</emphasis> specifies a name of variable whose values should be used as IRIs of resources that should be downloaded.
It is not an error if the variable is sometimes unbound or gets values that can not be converted to IRIs (e.g., integers) -- bad values are silently ignored.
It is also not an error if the IRI can not be retrieved, this makes IRI retrieval somewhat similar to &quot;best effort union&quot; in SQL.
This pragma can be used more than once to specify many variable names.
It is not an error if values of different variables result in same IRI or a variable gets same value many times -- no one IRI is retrieved more than once.</listitem>
  <listitem><emphasis>input:grab-iri</emphasis> specifies an IRI that should be retrieved before executing the rest of the query, if it is not in the <emphasis>DB.DBA.RDF_QUAD</emphasis> already.
This pragma can be used more than once to specify many IRIs.
The typical use of this pragma is querying a set of related resources when only one &quot;root&quot; resource IRI is known but even that resource is not loaded.</listitem>
  <listitem><emphasis>input:grab-all</emphasis> is the simplest possible way to enable the feature but the resulting performance can be very bad.
It turns all variables and IRI constants in all graph, subject and object fields of all triple patterns of the query into values for
<emphasis>input:grab-var</emphasis> and <emphasis>input:grab-iri</emphasis>,
so the SPARQL processor will dereference everything what might be related to the text of the query.</listitem>
  <listitem><emphasis>input:grab-seealso</emphasis> (and synonym <emphasis>input:grab-follow-predicate</emphasis>) specifies an IRI of an predicate similar to foaf:seeAlso.
Predicates of that sort suggest location of resources that contain more data about predicate subject.
The IRI dereferencing routine may use these predicates to find additional IRIs for loading resources.
This is especially useful when the text of the query comes from remote client and may lack triple patterns like
<emphasis><![CDATA[optional { ?id <SeeAlso> ?more }]]></emphasis> from the previous example.
The use of <emphasis>input:grab-seealso</emphasis> makes the SPARQL query nondeterministic, because the order and the number of retrieved documents will
depend on execution plan and they may change from run to run.
This pragma can be used more than once to specify many IRIs, but this feature is costly.
Every additional predicate may result in significant number of lookups in the RDF storage, affecting total execution time.</listitem>
  <listitem><emphasis>input:grab-limit</emphasis> should be an integer that is a maximum allowed number of resource retrievals.
The default value is pretty big (few millions of documents) so it is strongly recommended to set smaller value.
Set it even if you're absolutely sure that the set of resources is small, because program errors are always possible.
All resource downloads are counted, both successful and failed, both forced by <emphasis>input:grab-iri</emphasis> and forced by <emphasis>input:grab-var</emphasis>.
Nevertheless, all constant IRIs specified by <emphasis>input:grab-iri</emphasis> (or <emphasis>input:grab-all</emphasis>) are downloaded before the first check of the <emphasis>input:grab-limit</emphasis> counter,
so this limit will never prevent from downloading &quot;root&quot; resources.
</listitem>
  <listitem><emphasis>input:grab-depth</emphasis> should be an integer that is a maximum allowed number of query iterations.
Every iteration may find new IRIs to retrieve, because resources loaded on previous iteration may add these IRIs to <emphasis>DB.DBA.RDF_QUAD</emphasis> and make result set longer.
The default value is 1, so the SPARQL processor will retrieve only resources explicitly named in &quot;root&quot; resources or in quad that are in the database before the query execution.
</listitem>
  <listitem><emphasis>input:grab-base</emphasis> specifies a base IRI used to convert relative IRIs into absolute. The default is an empty string.</listitem>
  <listitem><emphasis>input:grab-resolver</emphasis> is a name of procedure that resolve IRIs and determines the HTTP method of retrieval.
The default is name of <emphasis>DB.DBA.RDF_GRAB_RESOLVER_DEFAULT()</emphasis> procedure that is described below.
If other procedure is specified, the signature should match to the default one.</listitem>
  <listitem><emphasis>input:grab-destination</emphasis> is to override the default behaviour of the IRI dereferencing and store all retrieved triples in a single graph.
This is convenient when there's no logical difference where any given triple comes from, and changes in remote resources will only add triples but not make cached triples obsolete.
A SPARQL query is usually faster when all graph IRIs are fixed and there are no graph group patterns with an unbound graph variable, so storing everything in one single graph is worth considering.
</listitem>
  <listitem><emphasis>input:grab-loader</emphasis> is a name of procedure that retrieve the resource via HTTP, parce it and store it.
The default is name of <emphasis>DB.DBA.RDF_SPONGE_UP()</emphasis> procedure; this procedure also used by IRI dereferencing for FROM clauses.
You will probably never need to write your own procedure of this sort but some Virtuoso plugins will provide ready-to-use functions that will retrieve non-RDF resources and extract their metadata as triples or
will implement protocols other than HTTP.
</listitem>
</itemizedlist>
<para>Default resolver procedure is <emphasis>DB.DBA.RDF_GRAB_RESOLVER_DEFAULT()</emphasis>. Note that the function produce two absolute URIs,
<emphasis>abs_uri</emphasis> and <emphasis>dest_uri</emphasis>. Default procedure returns two equal strings, but other may return different values,
e.g., return primary and permanent location of the resource as <emphasis>dest_uri</emphasis> and the fastest known mirror location as
<emphasis>abs_uri</emphasis> thus saving HTTP retrieval time. It can even signal an error to block the downloading of some unwanted resource.</para>
<programlisting><![CDATA[
DB.DBA.RDF_GRAB_RESOLVER_DEFAULT (
  in base varchar,         -- base IRI as specified by input:grab-base pragma
  in rel_uri varchar,      -- IRI of the resource as it is specified by input:grab-iri or a value of a variable
  out abs_uri varchar,     -- the absolute IRI that should be downloaded
  out dest_uri varchar,    -- the graph IRI where triples should be stored after download
  out get_method varchar ) -- the HTTP method to use, should be "GET" or "MGET".
]]></programlisting>
</sect2>
</sect1>
<sect1 id="rdfviews"><title>RDF Views -- Mapping Relational Data to RDF</title>
<para>
RDF Views map relational data into RDF and allow customizing RDF representation of locally stored RDF data.
To let SPARQL clients access relational data as well as physical RDF graphs in a single query, we introduce a declarative Meta Schema Language for mapping SQL Data to RDF Ontologies.
As a result, all types of clients can efficiently access all data stored on the server.
The mapping functionality dynamically generates RDF Data Sets for popular ontologies such as SIOC, SKOS, FOAF, and ATOM/OWL without disruption to the existing database infrastructure of Web 1.0 or Web 2.0 solutions.
RDF views are also suitable for declaring custom representation for RDF triples, e.g. property tables, where one row holds many single-valued properties.
</para>
<sect2 id="rdfviewsintro"><title>Introduction</title>
<para>
The Virtuoso RDF Views meta schema is a built-in feature of Virtuoso's SPARQL to SQL translator.
It recognizes triple patterns that refer to graphs for which an alternate representation is declared and translates these into SQL accordingly.
The main purpose of this is evaluating SPARQL queries against existing relational databases.
There exists previous work from many parties for rendering relational data as RDF and opening it to SPARQL access.
We can mention D2RQ, SPASQL, Squirrel RDF, DBLP and others.
The Virtuoso effort differs from these mainly in the following:
</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>Integration with a triple store.
Virtuoso can process a query for which some triple patterns will go to local or remote relational data and some to local physical RDF triples.
</listitem><listitem>SPARQL query can be used in any place where SQL can.
Database connectivity protocols are neutral to the syntax of queries they transmit, thus any SQL client, e.g. JDBC, ODBC or XMLA application, can send SPARQL queries and fetch result sets.
Moreover, a SQL query may contain SPARQL subqueries and SPARQL expressions may use SQL built-in functions and stored procedures.
</listitem><listitem>Integration with SQL.
Since SPARQL and SQL share the same run time and query optimizer, the query compilation decisions are always made with the best knowledge of the data and its location.
This is especially important when mixing triples and relational data or when dealing with relational data distributed across many outside databases.
</listitem><listitem>No limits on SPARQL.
It remains possible to make queries with unspecified graph or predicate against mapped relational data, even though these may sometimes be inefficient.
</listitem><listitem>Coverage of the whole relational model.
Multi-part keys etc. are supported in all places.
</listitem>
</itemizedlist>
</sect2>
<sect2 id="rdfviewrationale"><title>Rationale</title>
<para>
Since most of the data that is of likely use for the emerging semantic web is stored in relational databases, the argument for exposing this to SPARQL access is clear.
We note that historically, SQL access to relational data has essentially never been given to the public outside of the organization.
If programmatic access to corporate IS has been available to partners or the public, it has been through dynamic web pages or more recently web services.
There are reasons of performance, security, maintainability and so forth for this.
</para><para>
The culture of the emerging semantic web is however taking a different turn.
Since RDF and OWL offer a mergeable and queriable model for heterogeneous data, it is more meaningful and maintainable to expose selected data for outside query than it would be with SQL.
Advances in hardware make this also less of a performance issue than it would have been in the client-server database era.
</para><para>
In the context of Virtuoso, since Virtuoso is originally a virtual/federated database, incorporating SPARQL to relational mapping is an evident extension of the product's mission as a multi-protocol, multi-platform connector between information systems.
</para>
</sect2>
<sect2 id="rdfviewquadmapatternsvalueandiriclasses"><title>Quad Map Patterns, Value and IRI Classes</title>
<para>
In the simplest sense, any relational schema can be rendered into RDF by converting all primary keys and foreign keys into IRI's, assigning a predicate IRI to each column, and an rdf:type predicate for each row linking it to a RDF class IRI corresponding to the table.
Then a triple with the primary key IRI as subject, the column IRI as predicate and the column's value as object is considered to exist for each column that is neither part of a primary or foreign key.
</para><para>
Strictly equating a subject value to a row and each column to a predicate is often good but is too restrictive for the general case.
</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>Multiple triples with the same subject and predicate can exist.
</listitem><listitem>A single subject can get single-valued properties from multiple tables or in some cases stored procedures.
</listitem><listitem>An IRI value of a subject or other field of a triple can be composed from more than one SQL value, these values may reside in different columns, maybe in different joined tables.
</listitem><listitem>Some table rows should be excluded from mapping.
</listitem></itemizedlist>
<para>
Thus in the most common case the RDF meta schema should consist of independent transformations; the domain of each transformation is a result-set of some SQL <emphasis>SELECT</emphasis> statement and range is a set of triples.
The <emphasis>SELECT</emphasis> that produce the domain is quite simple: it does not use aggregate functions, joins and sorting, only inner joins and <emphasis>WHERE</emphasis> conditions.
There is no need to support outer joins in the RDF meta schema because NULLs are usually bad inputs for functions that produce IRIs.
In the rare cases when NULLs are OK for functions, outer joins can be encapsulated in SQL views.
The range of mapping can be described by a SPARQL triple pattern: a pattern field is a variable if it depends on table columns, otherwise it is a constant.
Values of variables in the pattern may have additional restrictions on datatypes, when datatypes of columns are known.
</para><para>
This common case of an RDF meta schema is implemented in Virtuoso, with one adjustment.
Virtuoso stores quads, not triples, using the graph field (G) to indicate that a triple belongs to some particular application or resource.
A SPARQL query may use quads from different graphs without large difference between G and the other three fields of a quad.
E.g., variable <emphasis>?g</emphasis> in expression <emphasis>GRAPH ?g {...}</emphasis> can be unbound.
SPARQL has special syntax for &quot;graph group patterns&quot; that is convenient for sets of triple patterns with a common graph, but it also has shorthands for common subject and predicate, so the difference is no more than in syntax.
There is only one feature that is specific for graphs but not for other fields: the SPARQL compiler can create restrictions on graphs according to <emphasis>FROM</emphasis> and <emphasis>FROM NAMED</emphasis> clauses.
</para><para>
Virtuoso RDF Views should offer the same flexibility with the graphs as SPARQL addressing physical triples.
A transformation cannot always be identified by the graph used for ranges because graph may be composed from SQL data. The key element of the meta schema is a &quot;<emphasis>quad map pattern</emphasis>&quot;.
A simple quad map pattern fully defines one particular transformation from one set of relational columns into triples that match one SPARQL graph pattern.
The main part of quad map pattern is four declarations of &quot;<emphasis>quad map values</emphasis>&quot;, each declaration specifies how to calculate the value of the corresponding triple field from the SQL data.
The pattern also lists boolean SQL expressions that should be used to filter out unwanted rows of source data (and to join multiple tables if source columns belong to different tables).
There are also quad map patterns that group together similar quad patterns but do not specify any real transformation or even prevent unwanted transformations from being used, they are described in &quot;Grouping Map Patterns&quot; below.
</para><para>
Quad map values refer to schema elements of two further types: &quot;IRI classes&quot; and &quot;literal classes&quot;.
</para>
<sect3 id="rdfviewiriclasses"><title>IRI Classes</title>
<para>
An IRI class declares that a column or set of columns gets converted into a IRI in a certain way.
The conversion of this sort can be declared revertible (bijection) so an IRI can be parsed into original SQL values; this is useful when some equality of an IRI constant and a calculated IRI can be replaced with an equality of a parse result of a constant and an SQL column that is index criteria or simply faster.
In addition, the SPARQL optimizer will eliminate redundant conversions if one IRI class is explicitly declared as a subclass of another.
The most flexible declaration for conversion consists of specifying functions that assemble and disassemble from IRI into its constituent parts.
This is overkill for typical conversions so it is possible to specify only one sprintf-style format string such that <emphasis>sprintf()</emphasis> SQL function will print an IRI using this format and <emphasis>sprintf_inverse()</emphasis> will be able to parse it back.
</para><para>The use of <emphasis>sprintf_inverse()</emphasis> assumes that the format does not contain fragments like <emphasis>'%s%s'</emphasis> that make it impossible to separate parts of IRI from each other.
</para><para>
In the following, we shall map the Virtuoso users and user roles system tables into the SIOC ontology.
</para>
<programlisting><![CDATA[
create iri class oplsioc:user_iri "http://myhost/sys/user?id=%d"
  (in uid integer not null) .
create iri class oplsioc:group_iri "http://myhost/sys/group?id=%d"
  (in gid integer not null) .
create iri class oplsioc:membership_iri
  "http://myhost/sys/membersip?super=%d&sub=%d"
  (in super integer not null, in sub integer not null) .
create iri class oplsioc:dav_iri "http://myhost%s"
  (in path varchar) .
]]></programlisting>
<para>
These IRI classes are used for mapping data from the <emphasis>DB.DBA.SYS_USERS</emphasis> and <emphasis>DB.DBA.SYS_ROLE_GRANTS</emphasis> system tables that are defined in Virtuoso as follows:
</para>
<programlisting><![CDATA[
create table DB.DBA.SYS_USERS (
  U_ID                integer not null unique,
  U_NAME              char (128) not null primary key,
  U_IS_ROLE           integer default 0,
  U_FULL_NAME         char (128),
  U_E_MAIL            char (128) default &quot;,
  U_ACCOUNT_DISABLED  integer default 1,
  U_DAV_ENABLE        integer default 0,
  U_SQL_ENABLE        integer default 1,
  U_HOME              varchar (128),
. . .
 );
]]></programlisting>
<para>
Single record in <emphasis>DB.DBA.SYS_USERS</emphasis> corresponds to a plain user or a group (role).
Users and roles are collectively named &quot;grantees&quot;. Thus a role may be granted to another role or to a user account.
A role grant may be direct (explicit) or assigned by recursion.
</para>
<programlisting><![CDATA[
create table SYS_ROLE_GRANTS (
  GI_SUPER   integer,
  GI_SUB     integer,
  GI_DIRECT  integer default 1,
. . .
  primary key (GI_SUPER, GI_SUB, GI_DIRECT));
]]></programlisting>
<para>
The following example demonstrates two things: function-based IRI class and the idea of IRI subclasses.
Classes <emphasis>oplsioc:user_iri</emphasis> and <emphasis>oplsioc:group_iri</emphasis> work fine for quad maps of <emphasis>U_ID</emphasis> if and only if the value of <emphasis>U_IS_ROLE</emphasis> is accordingly restricted to FALSE or TRUE, otherwise one may occasionally generate, say, user IRI for a group.
To create and parse IRIs that correspond to any U_IDs, two functions should be created:
</para>
<programlisting><![CDATA[
create function DB.DBA.GRANTEE_URI (in id integer)
returns varchar
{
  declare isrole integer;
  isrole := coalesce ((select top 1 U_IS_ROLE
      from DB.DBA.SYS_USERS where U_ID = id ) );
  if (isrole is null)
    return NULL;
  else if (isrole)
    return sprintf ('http://%s/sys/group?id=%d', id);
  else
    return sprintf ('http://%s/sys/user?id=%d', id);
};
]]></programlisting>
<programlisting><![CDATA[
create function DB.DBA.GRANTEE_URI_INVERSE (in id_iri varchar)
returns integer
{
  declare parts any;
  parts := sprintf_inverse (id_iri,
      'http://myhost/sys/user?id=%d', 1 );
  if (parts is not null)
    {
      if (exists (select top 1 1 from DB.DBA.SYS_USERS
          where U_ID = parts[0] and not U_IS_ROLE ) )
        return parts[0];
    }
  parts := sprintf_inverse (id_iri,
      'http://myhost/sys/group?id=%d', 1 );
  if (parts is not null)
    {
      if (exists (select top 1 1 from DB.DBA.SYS_USERS
          where U_ID = parts[0] and U_IS_ROLE ) )
        return parts[0];
    }
  return NULL;
};
]]></programlisting>
<para>
The next declaration creates an IRI class based on these two functions:
</para>
<programlisting><![CDATA[
create iri class oplsioc:grantee_iri using
  function DB.DBA.GRANTEE_URI (in id integer)
    returns varchar,
  function DB.DBA.GRANTEE_URI_INVERSE (in id_iri varchar)
    returns integer .
]]></programlisting>
<para>
In common case, IRI class declaration contains an N-array function that composes IRIs and N inverse functions that gets an IRI as an argument and extracts the Nth SQL value.
IRI composing function should silently return NULL on incorrect arguments instead of error signal.
Inverse functions should return NULL if the argument has an incorrect type or value.
</para>
<para>
It is possible to specify only composing function without any of inverse functions. However <emphasis>option (bijection)</emphasis> can not be used in that case, obviously.
</para>
</sect3>
<sect3 id="rdfviewliteralclasses"><title>Literal Classes</title>
<para>
A &quot;literal class&quot; declares that a column or set of columns gets converted into a literal instead of an IRI.
More precisely, the result of conversion can be <emphasis>IRI_ID</emphasis> so it represents an IRI, but in current version of Virtuoso this is supported only for some internal built-in literal classes, not for classes declared by the user.
So for user-defined literal class the result of the conversion is an RDF literal even if it is a string representation of a valid IRI.
</para><para>
In any case, a literal class can be used only in quad map values of O fields, because Virtuoso does not support literal values as subjects.
</para><para>
A special case of literal class is the identity class that converts a value from <emphasis>varchar</emphasis> column into an untyped literal and value from column of any other SQL datatype into a typed literal with type from XMLSchema set, i.e. <emphasis>xsd:integer</emphasis>, <emphasis>xsd:dateTime</emphasis> and so on.
Columns of types <emphasis>ANY</emphasis> and <emphasis>IRI_ID</emphasis> are not supported.
</para><para>
The SPARQL optimizer knows that RDF literal types are pairwise disjoint so literal classes that produce literals of different types are known to be pairwise disjoint.
The optimizer will replace a join on two disjoint literal classes with an empty statement, to simplify the resulting query.
</para>
</sect3>
<sect3 id="rdfviewbijandreturns"><title>BIJECTION and RETURNS Options</title>
<para>
There is one subtle problem with IRI class declarations.
To get benefit from a relational index, SPARQL optimizer should compose equality between table column and some known SQL value, not between return value of IRI class and a known composed IRI.
In addition, redundant calculations of IRIs takes time.
To enable this optimization, an IRI class declaration should end with <emphasis>option (bijection)</emphasis> clause.
</para>
<para>
The SPARQL compiler may produce big amounts of SQL code when the query contains equality of two calculated IRIs and these IRIs may come from many different IRI classes.
It is possible to provide hints that will let the compiler check if two IRI classes form disjoint sets of possible IRI values. The more disjoint sets are found the less possible combinations remain so the resulting SQL query will contain fewer unions of joins.
The SPARQL compiler can prove some properties of sprintf format strings. E.g., it can prove that set of all strings printed by &quot;http://example.com/item%d&quot; and the set of strings printed by &quot;http://example.com/item%d/&quot; are disjoint.
It can prove some more complicated statements about unions and intersections of sets of strings.
The IRI or literal class declaration may contain <emphasis>option (returns ...)</emphasis> clause that will specify one or more sprintf patterns that cover the set of generated values.
Consider a better version of IRI class declaration listed above:
</para>
<programlisting><![CDATA[
create iri class oplsioc:grantee_iri using
  function DB.DBA.GRANTEE_URI (in id integer)
    returns varchar,
  function DB.DBA.GRANTEE_URI_INVERSE (in id_iri varchar)
    returns integer
  option ( bijection,
    returns "http://myhost/sys/group?id=%d"
    union   "http://myhost/sys/user?id=%d" ) .
]]></programlisting>
<para>
It is very important to keep IRI classes easily distinguishable by the text of IRI string and easy to parse.
</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>Format <emphasis>%U</emphasis> is better than <emphasis>%s</emphasis>, especially in the middle of IRI, because the <emphasis>%U</emphasis> fragment can not contain characters like &quot;/&quot; or &quot;=&quot;; one may prove that <emphasis>/%U/</emphasis> and <emphasis>/abra%d/cadabra/</emphasis> are disjoint but <emphasis>/%s/</emphasis> and <emphasis>/abra%d/cadabra/</emphasis> are not disjoint.
</listitem><listitem>It is better when the variable part like <emphasis>%U</emphasis> or <emphasis>%d</emphasis> is placed between characters that may not occur in the <emphasis>%U</emphasis> or <emphasis>%d</emphasis> output, i.e. <emphasis>%U</emphasis> is placed between &quot;/&quot;, &quot;&amp;&quot; or &quot;=&quot; and <emphasis>%d</emphasis> is placed between non-digits; <emphasis>order_line_%d</emphasis> is better than <emphasis>order-line-%d</emphasis> because minus may be part of <emphasis>%d</emphasis> output.
</listitem><listitem>End-of-line is treated as a special character, so placing <emphasis>%U</emphasis> or <emphasis>%d</emphasis> between &quot;/&quot; and end of line is as good as placing it between two &quot;/&quot;.
</listitem></itemizedlist>
<para>
In some cases <emphasis>option (returns ...)</emphasis> can be used for IRI classes that are declared using sprintf format, but actual data have more specific format.
Consider a literal class declaration that is used to output strings and the application knows that all these strings are ISBN numbers:
</para>
<programlisting><![CDATA[
create literal class example:isbn_ref "%s" (in isbn varchar not null)
  option ( bijection, returns "%u-%u-%u-%u" union "%u-%u-%u-X" )
]]></programlisting>
<para>
Sometimes interoperability restrictions will force you to violate these rules but please try to follow them as often as possible.
</para>
</sect3>
<sect3 id="rdfviewsubclasses"><title>Subclasses</title>
<para>
Additional problem appears when the equality is between two IRIs of two different IRI classes.
Even if both of them are bijections, the compiler does not know if these IRI classes behave identically on the intersection of their domains.
To let the optimizer know this fact, one IRI class can be explicitly declared as a subclass of another:
</para>
<programlisting><![CDATA[
make oplsioc:user_iri subclass of oplsioc:grantee_iri .
make oplsioc:group_iri subclass of oplsioc:grantee_iri .
]]></programlisting>
<para>
The SPARQL compiler can not check the validity of a subclass declaration.
The developer should carefully test functions to ensure that transformations are really subclasses, as well as to ensure that functions of an IRI class declarations are really inverse to each other.
</para><para>
When declaring that a table's primary key is converted into a IRI according to one IRI class, one usually declares that all foreign keys referring to this class also get converted into an IRI as per this same class, or subclass of same class.
</para><para>
Subclasses can be declared for literal classes as well as for IRI classes, but this case is rare. The reason is that most of literals are made by identity literal classes that are disjoint to each other even if values may be equal in SQL sense, such as <emphasis>"2"</emphasis> of type <emphasis>xsd:integer</emphasis> and <emphasis>"2.0"</emphasis> of type <emphasis>xsd:double</emphasis>.
</para>
</sect3>
<sect3 id="rdfviewsimplequadmappatterns"><title>Simple Quad Map Patterns</title>
<para>
The following declaration of quad map pattern is self-explanatory. The line for <emphasis>object</emphasis> uses identity literal class so there's no need to specify its name.
</para>
<programlisting><![CDATA[
graph      <http://myhost/sys>
subject    oplsioc:user_iri (DB.DBA.SYS_USERS.U_ID)
predicate  foaf:email
object     DB.DBA.SYS_USERS.U_E_MAIL
]]></programlisting>
<para>
The description language also supports SPARQL-style notation that contains less keywords and eliminates duplicate graphs, subjects and predicates.
The following add two patterns with constant graph IRI <emphasis>&lt;http://myhost/sys&gt;</emphasis> and subjects are made from column <emphasis>DB.DBA.SYS_USERS.U_ID</emphasis> by <emphasis>oplsioc:user_iri</emphasis>.
</para>
<programlisting><![CDATA[
graph <http://myhost/sys>
  {
    oplsioc:user_iri (DB.DBA.SYS_USERS.U_ID)
      a sioc:user ;
      oplsioc:name DB.DBA.SYS_USERS.U_FULL_NAME .
  }
]]></programlisting>
</sect3>
<sect3 id="rdfviewassigningnamestoquadmappatterns"><title>Assigning Names To Quad Map Patterns</title>
<para>
In real applications, quad map patterns should be named, for schema manipulation and keeping debug info readable.
Thus it is much better to rewrite the previous example as
</para>
<programlisting><![CDATA[
create virtrdf:SysUsers as graph <http://myhost/sys>
  {
    oplsioc:user_iri (DB.DBA.SYS_USERS.U_ID)
      a sioc:user
          as virtrdf:SysUserType-User;
      oplsioc:name DB.DBA.SYS_USERS.U_FULL_NAME
          as virtrdf:SysUsersFullName .
  }
]]></programlisting>
<para>
Using these names, one may later write, say, <emphasis>drop quad map virtrdf:SysUserType-User</emphasis>.
</para><para>
One name, <emphasis>virtrdf:DefaultQuadMap</emphasis> is reserved.
It is an internal quad map pattern used to access &quot;native-form&quot; quads from <emphasis>DB.DBA.RDF_QUAD</emphasis>:
</para>
<programlisting><![CDATA[
create virtrdf:DefaultQuadMap as
graph rdfdf:default-iid-nonblank (DB.DBA.RDF_QUAD.G)
subject rdfdf:default-iid (DB.DBA.RDF_QUAD.S)
predicate rdfdf:default-iid-nonblank (DB.DBA.RDF_QUAD.P)
object rdfdf:default (DB.DBA.RDF_QUAD.O)
]]></programlisting>
<para>
IRI classes from <emphasis>rdfdf:...</emphasis> namespace are also reserved.
</para>
</sect3>
<sect3 id="rdfviewgroupingmappatterns"><title>Grouping Map Patterns</title>
<para>
The previous example actually contains three map patterns, not two.
The name <emphasis>virtrdf:SysUsers</emphasis> refers to a &quot;<emphasis>group map pattern</emphasis>&quot; that does not define any real transformation of relational data into RDF but helps organize quad map patterns into a tree.
Group may contain both quad map patterns and other groups.
A group can be manipulated as a whole, e.g. <emphasis>drop quad map virtrdf:SysUsers</emphasis> will remove all three map patterns.
</para>
</sect3>
</sect2>
<sect2 id="rdfviewconfiguringrdfstorages"><title>Configuring RDF Storages</title><para>
&quot;<emphasis>Quad Storage</emphasis>&quot; is a named set of quad patterns.
The declaration <emphasis>define input:storage storage-name</emphasis> states that a SPARQL query will be executed using only quad patterns of the given quad storage.
Declarations of IRI classes, literal classes and quad patterns are shared between all quad storages of an RDF meta schema but every quad storage contains only a subset of all available quad patterns.
Two quad storages are always defined:
</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>A <emphasis>virtrdf:default</emphasis> one usually consists of everything (all user-relational mappings plus <emphasis>virtrdf:DefaultQuadMap</emphasis> for &quot;native-form&quot; quads from <emphasis>DB.DBA.RDF_QUAD</emphasis>)
</listitem><listitem>A <emphasis>virtrdf:empty</emphasis> storage refers solely to <emphasis>DB.DBA.RDF_QUAD</emphasis> and can not be altered.
</listitem></itemizedlist>
<para>
Three statements for manipulating storages are
</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem><emphasis>create quad storage storage-name { quad-map-decls } .</emphasis> 
</listitem><listitem><emphasis>alter quad storage storage-name { quad-map-decls-or-drops } .</emphasis> 
</listitem><listitem><emphasis>drop quad storage storage-name . </emphasis>
</listitem></itemizedlist>
<para>
A map pattern can be created only as a part of <emphasis>create quad storage</emphasis> or <emphasis>alter quad storage</emphasis> statement, so initially it is used by exactly one storage.
It can be imported to some other storage using directive <emphasis>create map-id using storage source-storage</emphasis>. E.g., declarations of many storages create <emphasis>virtrdf:DefaultQuadMap</emphasis> using storage <emphasis>virtrdf:DefaultQuadStorage</emphasis>.
</para><para>
Only a &quot;top-level&quot; quad map pattern (standalone or a whole group with descendants) can be imported, member of a group can not.
The import directive also can not be a part of some group declaration.
</para><para>
The directive <emphasis>drop quad map map-name</emphasis> removes a map from one storage when it appears inside <emphasis>alter quad storage</emphasis> statement.
Otherwise it removes the map from all storages.
There exists garbage collection for quad map patterns, so any unused map is immediately deleted.
A group is deleted with all its descendants.
</para>
</sect2>
<sect2 id="rdfviewtranslationofpatterns"><title>Translation Of SPARQL Triple Patterns To Quad Map Patterns</title>
<para>
When a SPARQL query is compiled into SQL using a quad storage, every triple pattern should become a subquery that retrieves data from relational tables.
This subquery is an <emphasis>UNION ALL</emphasis> of joins generated from appropriate quad map patterns.
The complete SQL query is composed from these basic subqueries.
Thus the first operation of the SQL generation for a triple pattern is searching for quad map patterns that may in principle produce triples that match the triple pattern.
</para><para>
The more restrictions contained in the triple pattern the fewer quad map patterns will be used.
A triple pattern <emphasis>graph ?g { ?s ?p ?o }</emphasis> is common enough to invoke all data transformations of the storage.
A triple pattern <emphasis>graph &lt;g&gt; { ?s &lt;p&gt; &lt;o&gt; }</emphasis> will usually intersect with the range of only one quad map.
Sometimes it is possible to prove that the storage can not contain any data that matches the given triple pattern, hence zero number of members of <emphasis>UNION ALL</emphasis> will result in constantly empty result-set.
</para>
<para>The search for quad maps for a given pair of triple pattern and quad map storage is quite simple.
The storage is treated as a tree of map patterns where quad map patterns are leafs, grouping patterns are inner nodes and the whole storage is also treated as a grouping pattern that specify no fields and contains all top-level map patterns of the storage.
</para>
<para>
The tree is traversed from the root, left to right, non-leaf vertex are checked before their children.
The check of a vertex consists of up to four field checks, for G, S, P and O.
Every field check compares the field definition in the vertex and the corresponding field in the triple pattern, G and G, S and S and so on.
Note that a non-leaf vertex defines less than four of its fields, e.g., the root vertex does not define any of its fields and top-level <emphasis>graph map { ... }</emphasis> defines only graph.
Checks are performed only for defined fields and return one of three values: &quot;failed&quot;, &quot;passed&quot;, &quot;full match&quot;, according to the following rules:
</para>
<table><title>Matching Triple Field and Vertex Field</title>
<tgroup cols="3">
<thead><row>
<entry>Field of vertex</entry><entry>Field in triple pattern</entry><entry>Result</entry>
</row></thead>
<tbody>
<row><entry>constant</entry><entry>same constant</entry><entry>full match</entry></row>
<row><entry>constant</entry><entry>different constant</entry><entry>failed</entry></row>
<row><entry>constant</entry><entry>variable of same type</entry><entry>passed</entry></row>
<row><entry>constant</entry><entry>variable of different type</entry><entry>failed</entry></row>
<row><entry>quad map value</entry><entry>constant of same type</entry><entry>full match</entry></row>
<row><entry>quad map value</entry><entry>constant of different type</entry><entry>failed</entry></row>
<row><entry>quad map value of type X</entry><entry>variable, X or subtype of X</entry><entry>full match</entry></row>
<row><entry>quad map value of type X</entry><entry>variable, supertype of X</entry><entry>passed</entry></row>
<row><entry>quad map value of type X</entry><entry>variable, type does not intersect with X</entry><entry>failed</entry></row>
</tbody>
</tgroup>
</table>
<para>
If any of the checks fails, the vertex and all its children are excluded from the rest of processing.
Otherwise, if all four fields are defined for the quad map pattern, the map is added to the list of matching map patterns.
The difference between &quot;passed&quot; and &quot;full match&quot; is significant only if the map is declared with <emphasis>option (exclusive)</emphasis>
If all performed checks return &quot;full match&quot; and <emphasis>option (exclusive)</emphasis> is set then the traverse of the tree is stopped as soon as all children of the vertex are traversed.
The most typical use of this option is when the application developer is sure that all triples of a graph belong to his application and they come from his own quad map patterns, not from <emphasis>DB.DBA.RDF_QUAD</emphasis>.
This is to prevent the SPARQL compiler from generating redundant subqueries accessing <emphasis>DB.DBA.RDF_QUAD</emphasis>.
The declaration may look like
</para>
<programlisting><![CDATA[
create quad storage <mystorage>
  {
    graph <mygraph> option (exclusive) { . . . }
    create virtrdf:DefaultQuadMap
      using storage virtrdf:DefaultQuadStorage .
  }
]]></programlisting>
<para>
Exclusive patterns make the order of declarations important, because an exclusive declaration may &quot;throw a shadow&quot; on declarations after it.
Consider a database that have a special table RDF_TYPE that caches all RDF types of all subjects in all graphs.
Consider two declarations: all triples from graph <emphasis>&lt;http://myhost/sys&gt;</emphasis> and all triples with <emphasis>rdf:type</emphasis> predicate, both exclusive:
</para>
<programlisting><![CDATA[
graph <http://myhost/sys> option (exclusive)
  {
    . . . # mapping of DB.DBA.SYS_USERS as in previous examples.
  }
graph rdfdf:default-iid-nonblank (DB.DBA.RDF_TYPE.G)
subject rdfdf:default-iid (DB.DBA.RDF_TYPE.S)
predicate rdf:type
object rdfdf:default (DB.DBA.RDF_TYPE.O)
option (exclusive)
]]></programlisting>
<para>
The order of these declarations dictates that triple pattern
</para>
<programlisting><![CDATA[
graph <http://myhost/sys> {?s rdf:type ?o}
]]></programlisting>
<para>
is compiled using only quad map patterns of the graph declaration, ignoring second declaration (and of course ignoring default mapping rule, if any).
An explicit <emphasis>option (order N)</emphasis> at the end of quad map pattern will tweak the priority.
By default, order will grow from 1000 for the first declaration in the statement to 1999 for the last, explicit configuration is especially useful to make order persistent to <emphasis>alter storage</emphasis> statements.
</para>
<para>
The <emphasis>option (exclusive)</emphasis> trick is ugly, low-level and prone to cause compilation errors after altering storage declarations.
When misused, it is as bad as &quot;red cut&quot; in PROLOG, but one must use this trick to build scalable storages.
</para>
<para>
There is one exception from the rules described above.
This exception is for <emphasis>virtrdf:DefaultQuadStorage</emphasis> only.
If a graph variable of a quad map pattern is not bound and no source graph specified by <emphasis>FROM</emphasis> clauses then quad maps for specific constant graphs are ignored.
In other words, if a default quad storage contains quad maps for specific graphs then the query in that storage should explicitly specify the graph in order to use a map for graph.
This rule will not work if the default quad map is removed from the <emphasis>virtrdf:DefaultQuadStorage</emphasis>.
This rule relates to the default storage itself, not to the containing patterns; copying some or all patterns into other storage will not reproduce there this special effect.
</para>
</sect2>
<sect2 id="rdfviewdescribingsourcerelationaltables"><title>Describing Source Relational Tables</title><para>
Quad map patterns of an application usually share a common set of source tables and quad map values of one pattern usually share either a single table or very small number of joined tables.
Join and filtering conditions are also usually repeated in different patterns.
It is not necessary to type table descriptions multiple times, they are declare once in the beginning of storage declaration statement and shared between all quad map declarations inside the statement.
Names of aliases can be used instead of table names in quad map values.
</para>
<programlisting><![CDATA[
from DB.DBA.SYS_USERS as user where (^{user.}^.U_IS_ROLE = 0)
from DB.DBA.SYS_USERS as group where (^{group.}^.U_IS_ROLE = 1)
from DB.DBA.SYS_USERS as account
from user as active_user
  where (^{active_user.}^.U_ACCOUNT_DISABLED = 0)
from DB.DBA.SYS_ROLE_GRANTS as grant
  where (^{grant.}^.GI_SUPER = ^{account.}^.U_ID)
  where (^{grant.}^.GI_SUB = ^{group.}^.U_ID)
  where (^{grant.}^.GI_SUPER = ^{user.}^.U_ID)
]]></programlisting>
<para>
This declares five distinct aliases for two distinct tables, and six filtering conditions.
Every condition is an SQL expression with placeholders where a reference to the table should be printed.
The SPARQL compiler will not try to parse texts of these expressions (except dummy search for placeholders), so any logical expressions are acceptable.
When a quad map pattern declaration refers to some aliases, the <emphasis>WHERE</emphasis> clause of the generated SQL code will contain a conjunction of all distinct texts of &quot;relevant&quot; conditions.
A condition is relevant if every alias inside the condition is used in some quad map value of the map pattern, either directly or via clause like <emphasis>from user as active_user</emphasis>.
(<emphasis>user</emphasis> is a &quot;<emphasis>base alias</emphasis>&quot; for <emphasis>active_user</emphasis>).
</para><para>
Consider a group of four declarations.
</para>
<programlisting><![CDATA[
graph <http://myhost/sys>
  {
    oplsioc:user_iri (active_user.U_ID)
        a oplsioc:active-user .
    oplsioc:membership_iri (grant.GI_SUPER, grant.GI_SUB).
        oplsioc:is_direct
            grant.GI_DIRECT ;
        oplsioc:member-e-mail
            active_user.U_E_MAIL
               where (^{active_user.}^.U_E_MAIL like 'mailto:%').
    ldap:account-ref (account.U_NAME)
        ldap:belongs-to
            ldap:account-ref (group.U_NAME) option (using grant).
  }
]]></programlisting>
<para>
The first declaration will extend <emphasis>&lt;http://myhost/sys&gt;</emphasis> graph with one imaginary triples <emphasis>{ user a oplsioc:active-user }</emphasis> for every account record that is not a role and not disabled.
The second declaration deals with membership records.
A membership is a pair of a grantee (&quot;super&quot;) and a granted role (&quot;sub&quot;) stored as a row in <emphasis>DB.DBA.SYS_ROLE_GRANTS</emphasis>).
</para><para>
The second declaration states that every membership has <emphasis>oplsioc:is_direct</emphasis> property with value from <emphasis>GI_DIRECT</emphasis> column of that table (roles may be granted to other roles and users, so permissions are &quot;direct&quot; or &quot;recursive&quot;).
</para><para>
The third declaration declares <emphasis>oplsioc:member-e-mail</emphasis> property of memberships.
The value is a literal string from <emphasis>DB.DBA.SYS_USERS.U_E_MAIL</emphasis>, if the grantee is active (not disabled) and is not a role and its e-mail address starts with <emphasis>'mailto:'</emphasis>.
The join between <emphasis>DB.DBA.SYS_ROLE_GRANTS</emphasis> and <emphasis>DB.DBA.SYS_USERS</emphasis> is made by equality <emphasis>(GI_SUPER = U_ID)</emphasis> because the alias <emphasis>active_user</emphasis> in the declaration &quot;inherits&quot; all conditions specified for <emphasis>user</emphasis>.
In addition, the SPARQL compiler will add one more condition to check if the <emphasis>U_E_MAIL</emphasis> is not null because the NULL value is not a valid object and it knows that <emphasis>U_E_MAIL</emphasis> is not declared as <emphasis>NOT NULL</emphasis>.
</para><para>
The last declaration contains an <emphasis>option</emphasis> clause.
As usual, this indicates that the basic functionality is good for many tasks but not for all.
In this declaration, the <emphasis>ldap:belongs-to</emphasis> property establishes a relation between grantee (subject) and a granted role (object).
Both subject and object IRIs are based on account name, <emphasis>DB.DBA.SYS_USERS.U_NAME</emphasis>, so the quad map pattern contains two references to different aliases of <emphasis>DB.DBA.SYS_USERS</emphasis> but no alias for <emphasis>DB.DBA.SYS_ROLE_GRANTS</emphasis>.
Hence the declaration could produce a triple for every row of the Cartesian product of the <emphasis>DB.DBA.SYS_USERS</emphasis>.
To fix the problem, <emphasis>option (using alias-name)</emphasis> tells the compiler to process the alias-name as if it's used in some quad map value of the pattern.
</para><para>
It is an error to use an alias only in <emphasis>where</emphasis> clause of the quad map pattern but neither in values or in <emphasis>option (using alias-name)</emphasis>.
To detect more typos, an alias used in quad map values can not appear in <emphasis>option (using alias-name)</emphasis> clause.
</para>
</sect2>
<sect2 id="rdfmetadatarecovery"><title>RDF Metadata Maintainance and Recovery</title>
   <para>
     To detect and fix automatically most popular sorts of RDF metadata corruption use <link linkend="fn_rdf_audit_metadata"><function>DB.DBA.RDF_AUDIT_METADATA</function></link>.
It is also possible to backup RDF data by
    <link linkend="fn_rdf_backup_metadata"><function>DB.DBA.RDF_BACKUP_METADATA</function></link>
and restore the saved state later by using
    <link linkend="fn_rdf_restore_metadata"><function>DB.DBA.RDF_RESTORE_METADATA</function></link>.
It is convenient to make a backup before any modification of quad storages, quad map patterns or IRI classes, especially during debugging new RDF Views.
   </para>
</sect2>
</sect1>
<sect1 id="rdfsparqlimplementationextent"><title>SPARQL Implementation</title>


<para>Virtuoso's RDF support is at an early implementation  stage. The SPARQL language is fairly complete but none of the support functions such as data loading or triple storage are optimized. Many pieces of the present implementation that are written in Virtuoso/PL will be rewritten in C for performance.</para>
<para>Also, the triple store has no specific security model. Thus access rights of the tables and stored procedures involved in the process dictate who can access these features.</para>
<para>All triples of all graphs are stored in a single default system table called
<emphasis>DB.DBA.RDF_QUAD</emphasis>. This will change in the next release, where a complex meta-schema system will be introduced for allowing graphs to be stored in different tables, potentially having different index structures, optionally also full text index on long object values. The meta-schema support will also make it possible to map native
 SQL tables into the RDF SPARQL-queriable space, as well as introduce finer-grained security.</para>
<para>Hence the RDF subsystem is offered for  review but is not a productized whole. Benchmark results obtained with it are tentative and reflect a non-optimized state.</para>

<para>The current implementation does not support some SPARQL features.</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>Unicode characters in names are not supported.</listitem>
<listitem>Comments inside SPARQL query are not supported when   the query is inlined in SQL code.</listitem>
</itemizedlist>
<para>On the other hand, Virtuoso implements some extensions to SPARQL. One extension, <emphasis>DEFINE ...</emphasis> clause, e.g., <emphasis>define output:valmode "LONG"</emphasis> is described above.</para>

<para>Virtuoso also allows use of expressions in some places where
SPARQL only allows constant expressions or variables. For example,
the values list of SELECT may contain arbitrary expressions in parenthesis
as well as variable names. Expressions may also appear in triples of
CONSTRUCT pattern or WHERE pattern: an expression can be used instead
of constant or variable name for subject, predicate or object. In this
case, an expression is surrounded by backquotes.</para>

<para>The following return all distinct 'fragment' parts of all subjects in all graphs that have some predicate whose value is equal to 2+2.</para>
<programlisting><![CDATA[
SQL>sparql select distinct (bif:subseq (?s, bif:strchr (?s, '#')))
   where {
     graph ?g {
       ?s ?p `2+2` .
       filter (! bif:isnull (bif:strchr (?s, '#') ) )
     } };

callret
VARCHAR
----------
#four
]]></programlisting>
<para>
This is BNF grammar of SPARQL with all Virtuoso extensions, but without rules for syntax of lexems.
Rule numbers in square brackets are from W3C normative SPARQL grammar,
asterisk means that the rule differs from W3C grammar due to Virtuoso extensions,
<emphasis>[Virt]</emphasis> means that the rule is Virtuoso-specific.
<emphasis>[DML]</emphasis> stands for data manipulation language extensions from SPARUL.
</para>
<programlisting><![CDATA[
[1]*	Query		 ::=  Prolog ( QueryBody | SparulAction* | ( QmStmt ('.' QmStmt)* '.'? ) )
[1]	QueryBody	 ::=  SelectQuery | ConstructQuery | DescribeQuery | AskQuery
[2]*	Prolog		 ::=  Define* BaseDecl? PrefixDecl*
[Virt]	Define		 ::=  'DEFINE' QNAME (QNAME | Q_IRI_REF | String )
[3]	BaseDecl	 ::=  'BASE' Q_IRI_REF
[4]	PrefixDecl	 ::=  'PREFIX' QNAME_NS Q_IRI_REF
[5]*	SelectQuery	 ::=  'SELECT' 'DISTINCT'? ( ( Retcol ( ','? Retcol )* ) | '*' )
			DatasetClause* WhereClause SolutionModifier
[6]	ConstructQuery	 ::=  'CONSTRUCT' ConstructTemplate DatasetClause* WhereClause SolutionModifier
[7]*	DescribeQuery	 ::=  'DESCRIBE' ( VarOrIRIrefOrBackquoted+ | '*' ) DatasetClause* WhereClause? SolutionModifier
[8]	AskQuery	 ::=  'ASK' DatasetClause* WhereClause
[9]	DatasetClause	 ::=  'FROM' ( DefaultGraphClause | NamedGraphClause )
[10]*	DefaultGraphClause	 ::=  SourceSelector SpongeOptionList?
[11]*	NamedGraphClause	 ::=  'NAMED' SourceSelector SpongeOptionList?
[Virt]	SpongeOptionList	 ::=  'OPTION' '(' ( SpongeOption ( ',' SpongeOption )* )? ')'
[Virt]	SpongeOption	 ::=  QNAME PrecodeExpn
[Virt]	PrecodeExpn	 ::=  Expn	(* Only global variables can occur in Expn, local can not *)
[13]	WhereClause	 ::=  'WHERE'? GroupGraphPattern
[14]	SolutionModifier	 ::=  OrderClause? LimitClause? OffsetClause?
[15]	OrderClause	 ::=  'ORDER' 'BY' OrderCondition+
[16]*	OrderCondition	 ::=  ( 'ASC' | 'DESC' )? ( FunctionCall | Var | ( '(' Expn ')' ) | ( '[' Expn ']' ) )
[17]	LimitClause	 ::=  'LIMIT' INTEGER
[18]	OffsetClause	 ::=  'OFFSET' INTEGER
[19]	GroupGraphPattern	 ::=  '{' GraphPattern '}'
[20]	GraphPattern	 ::=  Triples? ( GraphPatternNotTriples '.'? GraphPattern )?
[21]	GraphPatternNotTriples	 ::=  OptionalGraphPattern | GroupOrUnionGraphPattern | GraphGraphPattern | Constraint
[22]	OptionalGraphPattern	 ::=  'OPTIONAL' GroupGraphPattern
[23]	GraphGraphPattern	 ::=  'GRAPH' VarOrBlankNodeOrIRIref GroupGraphPattern
[24]	GroupOrUnionGraphPattern	 ::=  GroupGraphPattern ( 'UNION' GroupGraphPattern )*
[25]*	Constraint	 ::=  'FILTER' ( ( '(' Expn ')' ) | BuiltInCall | FunctionCall )
[26]*	ConstructTemplate	 ::=  '{' ConstructTriples '}'
[27]	ConstructTriples	 ::=  ( Triples1 ( '.' ConstructTriples )? )?
[28]	Triples		 ::=  Triples1 ( '.' Triples? )?
[29]	Triples1	 ::=  VarOrTerm PropertyListNotEmpty | TriplesNode PropertyList
[30]	PropertyList	 ::=  PropertyListNotEmpty?
[31]	PropertyListNotEmpty	 ::=  Verb ObjectList ( ';' PropertyList )?
[32]*	ObjectList	 ::=  ObjGraphNode ( ',' ObjectList )?
[Virt]	ObjGraphNode	 ::=  GraphNode TripleOptions?
[Virt]	TripleOptions	 ::=  'OPTION' '(' TripleOption ( ',' TripleOption )? ')'
[Virt]	TripleOption	 ::=  'INFERENCE' ( QNAME | Q_IRI_REF | SPARQL_STRING )
[33]	Verb		 ::=  VarOrBlankNodeOrIRIref | 'a'
[34]	TriplesNode	 ::=  Collection | BlankNodePropertyList
[35]	BlankNodePropertyList	 ::=  '[' PropertyListNotEmpty ']'
[36]	Collection	 ::=  '(' GraphNode+ ')'
[32]	ObjectList	 ::=  GraphNode ( ',' ObjectList )?
[37]	GraphNode	 ::=  VarOrTerm | TriplesNode
[38]	VarOrTerm	 ::=  Var | GraphTerm
[39]*	VarOrIRIrefOrBackquoted	 ::=  Var | IRIref | Backquoted
[40]*	VarOrBlankNodeOrIRIrefOrBackquoted	 ::=  Var | BlankNode | IRIref | Backquoted
[Virt]	Retcol	 ::=  ( Var | ( '(' Expn ')' ) | RetAggCall ) ( 'AS' ( VAR1 | VAR2 ) )?
[Virt]	RetAggCall	 ::=  AggName '(', ( '*' | ( 'DISTINCT'? Var ) ) ')'
[Virt]	AggName	 ::=  'COUNT' | 'AVG' | 'MIN' | 'MAX' | 'SUM'
[41]*	Var	 ::=  VAR1 | VAR2 | GlobalVar
[Virt]	GlobalVar	 ::=  QUEST_COLON_PARAMNAME | DOLLAR_COLON_PARAMNAME | QUEST_COLON_PARAMNUM | DOLLAR_COLON_PARAMNUM
[42]*	GraphTerm	 ::=  IRIref | RDFLiteral | ( '-' | '+' )? NumericLiteral | BooleanLiteral | BlankNode | NIL | Backquoted
[Virt]	Backquoted	 ::=  '`' Expn '`'
[43]	Expn		 ::=  ConditionalOrExpn
[44]	ConditionalOrExpn	 ::=  ConditionalAndExpn ( '||' ConditionalAndExpn )*
[45]	ConditionalAndExpn	 ::=  ValueLogical ( '&&' ValueLogical )*	[46]	ValueLogical	 ::=  RelationalExpn
[47]*	RelationalExpn	 ::=  NumericExpn ( ( ('='|'!='|'<'|'>'|'<='|'>='|'LIKE') NumericExpn ) | ( 'IN' '(' Expns ')' ) )?
[49]	AdditiveExpn	 ::=  MultiplicativeExpn ( ('+'|'-') MultiplicativeExpn )*
[50]	MultiplicativeExpn	 ::=  UnaryExpn ( ('*'|'/') UnaryExpn )*
[51]	UnaryExpn	 ::=   ('!'|'+'|'-')? PrimaryExpn
[58]	PrimaryExpn	 ::=
			BracketedExpn | BuiltInCall | IRIrefOrFunction
			| RDFLiteral | NumericLiteral | BooleanLiteral | BlankNode | Var
[55]	IRIrefOrFunction	 ::=  IRIref ArgList?
[52]*	BuiltInCall	 ::=
			( 'STR' '(' Expn ')' )
			| ( 'IRI' '(' Expn ')' )
			| ( 'LANG' '(' Expn ')' )
			| ( 'LANGMATCHES' '(' Expn ',' Expn ')' )
			| ( 'DATATYPE' '(' Expn ')' )
			| ( 'BOUND' '(' Var ')' )
			| ( 'isIRI' '(' Expn ')' )
			| ( 'isURI' '(' Expn ')' )
			| ( 'isBLANK' '(' Expn ')' )
			| ( 'isLITERAL' '(' Expn ')' )
			| RegexExpn
[53]	RegexExpn	 ::=  'REGEX' '(' Expn ',' Expn ( ',' Expn )? ')'
[54]	FunctionCall	 ::=  IRIref ArgList
[56]*	ArgList	 ::=  ( NIL | '(' Expns ')' )
[Virt]	Expns	 ::=  Expn ( ',' Expn )*
[59]	NumericLiteral	 ::=  INTEGER | DECIMAL | DOUBLE
[60]	RDFLiteral	 ::=  String ( LANGTAG | ( '^^' IRIref ) )?
[61]	BooleanLiteral	 ::=  'true' | 'false'
[63]	IRIref		 ::=  Q_IRI_REF | QName
[64]	QName		 ::=  QNAME | QNAME_NS
[65]*	BlankNode	 ::=  BLANK_NODE_LABEL | ( '[' ']' )
[DML]	SparulAction	 ::=
			CreateAction | DropAction | LoadAction
			| InsertAction | DeleteAction | ModifyAction | ClearAction
[DML]*	CreateAction	 ::=  'CREATE' 'SILENT' ? 'GRAPH' ( 'IDENTIFIED' 'BY' )? PrecodeExpn
[DML]*	InsertAction	 ::=
			'INSERT' ( ( 'IN' | 'INTO ) 'GRAPH' ( 'IDENTIFIED' 'BY' )? )? PrecodeExpn
			ConstructTemplate ( DatasetClause* WhereClause SolutionModifier )?
[DML]*	DeleteAction	 ::=
			'DELETE' ( 'FROM' 'GRAPH' ( 'IDENTIFIED' 'BY' )? )? PrecodeExpn
			ConstructTemplate ( DatasetClause* WhereClause SolutionModifier )?
[DML]*	ModifyAction	 ::=
			'MODIFY' ( 'GRAPH' ( 'IDENTIFIED' 'BY' )? PrecodeExpn?
			'DELETE' ConstructTemplate 'INSERT' ConstructTemplate
			( DatasetClause* WhereClause SolutionModifier )?
[DML]*	ClearAction	 ::=  'CLEAR' ( 'GRAPH' ( 'IDENTIFIED' 'BY' )? PrecodeExpn )?
[DML]*	LoadAction	 ::=  'LOAD' PrecodeExpn ( ( 'IN' | 'INTO' ) 'GRAPH' ( 'IDENTIFIED' 'BY' )? PrecodeExpn )?
[DML]*	DropAction	 ::=  'DROP' 'SILENT'? ( 'GRAPH' ( 'IDENTIFIED' 'BY' )? PrecodeExpn )?
[Virt]	QmStmt		 ::=  QmSimpleStmt | QmCreateStorage | QmAlterStorage
[Virt]	QmSimpleStmt	 ::=
			QmCreateIRIClass | QmCreateLiteralClass | QmDropIRIClass | QmDropLiteralClass
			| QmCreateIRISubclass | QmDropQuadStorage | QmDropQuadMap
[Virt]	QmCreateIRIClass	 ::=  'CREATE' 'IRI' 'CLASS' QmIRIrefConst
			( ( String QmSqlfuncArglist )
			| ( 'USING' QmSqlfuncHeader ',' QmSqlfuncHeader ) )
[Virt]	QmCreateLiteralClass	 ::=  'CREATE' 'LITERAL' 'CLASS' QmIRIrefConst
			'USING' QmSqlfuncHeader ',' QmSqlfuncHeader QmLiteralClassOptions?
[Virt]	QmDropIRIClass	 ::=  'DROP' 'IRI' 'CLASS' QmIRIrefConst
[Virt]	QmDropLiteralClass	 ::=  'DROP' 'LITERAL' 'CLASS' QmIRIrefConst
[Virt]	QmCreateIRISubclass	 ::=  'IRI' 'CLASS' QmIRIrefConst 'SUBCLASS' 'OF' QmIRIrefConst
[Virt]	QmIRIClassOptions	 ::=  'OPTION' '(' QmIRIClassOption (',' QmIRIClassOption)* ')'
[Virt]	QmIRIClassOption	 ::=
			'BIJECTION'
			| 'RETURNS' STRING ('UNION' STRING)*
[Virt]	QmLiteralClassOptions	 ::=  'OPTION' '(' QmLiteralClassOption (',' QmLiteralClassOption)* ')'
[Virt]	QmLiteralClassOption	 ::=
			( 'DATATYPE' QmIRIrefConst )
			| ( 'LANG' STRING )
			| ( 'LANG' STRING )
			| 'BIJECTION'
			| 'RETURNS' STRING ('UNION' STRING)*
[Virt]	QmCreateStorage	 ::=  'CREATE' 'QUAD' 'STORAGE' QmIRIrefConst QmSourceDecl* QmMapTopGroup
[Virt]	QmAlterStorage	 ::=  'ALTER' 'QUAD' 'STORAGE' QmIRIrefConst QmSourceDecl* QmMapTopGroup
[Virt]	QmDropStorage	 ::=  'DROP' 'QUAD' 'STORAGE' QmIRIrefConst
[Virt]	QmDropQuadMap	 ::=  'DROP' 'QUAD' 'MAP' 'GRAPH'? QmIRIrefConst
[Virt]	QmDrop	 ::=  'DROP' 'GRAPH'? QmIRIrefConst
[Virt]	QmSourceDecl	 ::=
			( 'FROM' QTABLE 'AS' PLAIN_ID QmTextLiteral* )
			| ( 'FROM' PLAIN_ID 'AS' PLAIN_ID QmTextLiteral* )
			| QmCondition
[Virt]	QmTextLiteral	 ::=  'TEXT' 'XML'? 'LITERAL' QmSqlCol ( 'OF' QmSqlCol )? QmTextLiteralOptions?
[Virt]	QmTextLiteralOptions	 ::=  'OPTION' '(' QmTextLiteralOption ( ',' QmTextLiteralOption )* ')'
[Virt]	QmMapTopGroup	 ::=  '{' QmMapTopOp ( '.' QmMapTopOp )* '.'? '}'
[Virt]	QmMapTopOp	 ::=  QmMapOp | QmDropQuadMap | QmDrop
[Virt]	QmMapGroup	 ::=  '{' QmMapOp ( '.' QmMapOp )* '.'? '}'
[Virt]	QmMapOp		 ::=
			( 'CREATE' QmIRIrefConst 'AS' QmMapIdDef )
			| ( 'CREATE' 'GRAPH'? QmIRIrefConst 'USING' 'STORAGE' QmIRIrefConst QmOptions? )
			| ( QmNamedField+ QmOptions? QmMapGroup )
			| QmTriples1
[Virt]	QmMapIdDef	 ::=  QmMapTriple | ( QmNamedField+ QmOptions? QmMapGroup )
[Virt]	QmMapTriple	 ::=  QmFieldOrBlank QmVerb QmObjField
[Virt]	QmTriples1	 ::=  QmFieldOrBlank QmProps
[Virt]	QmNamedField	 ::=  ('GRAPH'|'SUBJECT'|'PREDICATE'|'OBJECT') QmField
[Virt]	QmProps		 ::=  QmProp ( ';' QmProp )?
[Virt]	QmProp		 ::=  QmVerb QmObjField ( ',' QmObjField )*
[Virt]	QmObjField	 ::=  QmFieldOrBlank QmCondition* QmOptions?
[Virt]	QmIdSuffix	 ::=  'AS' QmIRIrefConst
[Virt]	QmVerb		 ::=  QmField | ( '[' ']' ) | 'a'
[Virt]	QmFieldOrBlank	 ::=  QmField | ( '[' ']' )
[Virt]	QmField		 ::=
			NumericLiteral
			| RdfLiteral
			| ( QmIRIrefConst ( '(' ( QmSqlCol ( ',' QmSqlCol )* )? ')' )? )
			| QmSqlCol
[Virt]	QmCondition	 ::=  'WHERE' ( ( '(' SQLTEXT ')' ) | String )
[Virt]	QmOptions	 ::=  'OPTION' '(' QmOption ( ',' QmOption )* ')'
[Virt]	QmOption	 ::=  'EXCLUSIVE' | ( 'ORDER' INTEGER ) | ( 'USING' PLAIN_ID )
[Virt]	QmSqlfuncHeader	 ::=  'FUNCTION' SQL_QTABLECOLNAME QmSqlfuncArglist 'RETURNS' QmSqltype
[Virt]	QmSqlfuncArglist	 ::=  '(' ( QmSqlfuncArg ( ',' QmSqlfuncArg )* )? ')'
[Virt]	QmSqlfuncArg	 ::=  ('IN' | QmSqlId) QmSqlId QmSqltype
[Virt]	QmSqltype	 ::=  QmSqlId ( 'NOT' 'NULL' )?
[Virt]	QmSqlCol	 ::=  QmSqlId | spar_qm_sql_id
[Virt]	QmSqlId		 ::=  PLAIN_ID | 'TEXT' | 'XML'
[Virt]	QmIRIrefConst	 ::=  IRIref | ( 'IRI' '(' String ')' )
]]></programlisting>
<sect2 id="rdfsparqlandxquery"><title>SPARQL and XQuery</title>
<para>In the current implementation, the XQuery Function Library is not available from SPARQL.</para>
<para>As a temporary workaround, string parsing functions are made available, because they are widely used in W3C DAWG examples and the like. They are:</para>
<programlisting>
xsd:boolean (in strg any) returns integer
xsd:dateTime (in strg any) returns datetime
xsd:double (in strg varchar) returns double precision
xsd:float (in strg varchar) returns float
xsd:integer (in strg varchar) returns integer
</programlisting>
<para>(assuming that the query contains declaration 'PREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;')</para>
</sect2>
</sect1>

<sect1 id="rdfsparqlrule"><title>RDF Inference in Virtuoso</title>
<sect2 id="rdfsparqlruleintro"><title>Introduction</title>
<para>Virtuoso SPARQL can use an inference context for inferring triples that are not physically stored.
Such an inference context can be built from one or more graphs containing RDF Schema triples. The supported
RDF Schema or OWL constraints are imported from these graphs and are grouped together into rule bases.
A rule base is a persistent entity that can be referenced by a SPARQL query or end point. Queries running
with a given rule base work as if the triples asserted by this rule base were included in the graph or graphs accessed by the query.
</para>
<para>As of version 5.0, Virtuoso recognizes <emphasis>rdfs:subClassOf</emphasis> and <emphasis>rdfs:subPropertyOf</emphasis>.
Other RDF Schema or OWL information is not taken into account.
</para>
</sect2>
<sect2 id="rdfsparqlrulemake"><title>Making Rule Sets</title>
<para>Since RDF Schema and OWL schemas are RDF graphs, these can be loaded into the triple store. Thus, in order to use
such a schema as query context, one first loads the corresponding document into the triple store using <emphasis>ttlp</emphasis> or
<emphasis>rdf_load_rdfxml</emphasis> or related functions. After the schema document is loaded, one can add the assertions therein
into an inference context with the <emphasis>rdfs_rule_set</emphasis> function. This function specifies a logical name for the rule
set plus a graph URI. It is possible to combine multiple schema graphs into a single rule set. A single schema
graph may also independently participate in multiple rule sets.
</para>
<programlisting>
rdfs_rule_set (in name varchar, in uri varchar, in remove int := 0)
</programlisting>
<para>This function adds the applicable facts of the graph into a rule set. The graph URI must correspond
to the graph IRI of a graph stored in the triple store of the Virtuoso instance. If the remove argument
is true, the specified graph is removed from the rule set instead.
</para>
</sect2>
<sect2 id="rdfsparqlrulechange"><title>Changing Rule Sets</title>
<para>Changing a rule set affects queries made after the change. Some queries may have been previously
compiled and will not be changed as a result of modifying the rule set. When a rule set is changed, i.e.
when <emphasis>rdfs_rule_set</emphasis> is called with the first argument set to a pre-existing rule set's name, all the graphs
associated with this name are read and the relevant facts are added to a new empty rule set. Thus, if
triples are deleted from or added to the graphs comprising the rule set, calling <emphasis>rdfs_rule_set</emphasis> will refresh
the rule set to correspond to the state of the stored graphs.
</para>
</sect2>
<sect2 id="rdfsparqlrulesubclassandsubprop"><title>Subclasses and Subproperties</title>
<para>Virtuoso SPARQL supports RDF Schema subclasses and subproperties.
</para>
<para>The predicates <emphasis>rdfs:subClassOf</emphasis> and <emphasis>rdfs:subPropertyOf</emphasis> are
recognized when they appear in graphs included in a rule set. When such a rule set is specified as a context
for a SPARQL query, the following extra triples are generated as needed.
</para>
<para>For every <emphasis>?s rdf:type ?class</emphasis>, a triple <emphasis>?s rdf:type ?superclass</emphasis> is considered to exist,
such that <emphasis>?superclass</emphasis> is a direct or indirect superclass of <emphasis>?class</emphasis>. Direct superclasses are
declared with the <emphasis>rdfs:subClassOf</emphasis> predicate in the rule set graph. Transitivity of superclasses
is automatically taken into account, meaning that if a is a superclass of b and b a superclass of c,
then a is a superclass of c also. Cyclic superclass relations are not allowed. If such occur in the rule set data,
the behavior is undefined but will not involve unterminating recursion.
</para>
<para>For every <emphasis>?s ?subpredicate ?o</emphasis>, a triple <emphasis>?s ?superpredicate ?o</emphasis>
is considered to exist if the rule context declares <emphasis>?superpredicate</emphasis> to be a superpredicate
of <emphasis>?predicate</emphasis>. This is done by having the triple <emphasis>?subpredicate rdfs:subPropertyOf ?superpredicate</emphasis>
as part of the graphs making up the rule context. Transitivity is observed, thus if a is a subpredicate of b and b
a subpredicate of c, then a is also a subpredicate of c.
</para>
</sect2>
<sect2 id="rdfsameas"><title>OWL same-as Support</title>
<para>
Virtuoso has limited support for the OWL same-as predicate.
</para>
<para>
In the following, the abbreviation owl:same-as is used for  the IRI http://www.w3.org/2002/07/owl#same-as .
</para>
<para>
If same-as traversal is enabled and a triple pattern with a given
subject or object is being matched, all the synonyms of the S and O
will be tried and results gfenerated for all the tried bindings of S
and O.  The set of synonyms is generated at run time by following all
owl:same-as triples where the IRI in question is either the subject or
the object.  These are followed recursively from object to subject and
subject to object until the complete transitive closure is generated.
All same-as triples from all the graphs applicable to instantiating
the triple pattern at hand are considered.
</para>
<para>
Thus, if we have 
</para>
<programlisting><![CDATA[
<thing> <owl:same-as> <gizmo> .
<thing> <label> "thingy" .
]]></programlisting>
<para>
and we instantiate <emphasis>?s &lt;label> "thingy"</emphasis>
we get <emphasis>?s</emphasis> bound to <emphasis>&lt;thing></emphasis>.
</para>
<para>
If we instantiate <emphasis>&lt;gizmo> &lt;label> ?l</emphasis>
we get <emphasis>?l</emphasis> bound to <emphasis>"thingy"</emphasis> because the subject was given and it was expanded to its synonyms.
</para>
<para>
If binding a variable in a pattern where the variable was free, we do not expand the value to the complete set of its synonyms.
</para>
<para>
Same-as expansion is enabled in a query by <emphasis>define input:same-as "yes"</emphasis> in the beginning of the SPARQL query.
This has a significant run time cost but is in some cases useful when joining data between sets which are mapped to each other with same-as.
</para>
<para>
We note that the number of same-as expansions will depend on the join order used for the SPARQL query.
The compiler does not know the number of synonyms and cannot set the join order accordingly.
Regardless of the join order we will however get at least one IRI of the each synonym set as answer.
Also when interactively navigating a graph with a browser, the same-as expansion will take all synonyms into account.
</para>
<para>
For getting the complete entaiment of same-as, a forward
chaining approach should be used, effectivelty asserting all the
implied triples.
</para>
</sect2>
<sect2 id="rdfsparqlruleintro"><title>Implementation</title>
<para>Triples entailed by subclass or subproperty statements in an inference context are not physically stored.
Such triples are added to the result set by the query run time as needed. Also queries involving subclass or subproperty
rules are not rewritten into unions of all the possible triple patterns that might imply the pattern that is requested.
Instead, the SQL compiler adds special nodes that iterate over subclasses or subproperties at run time. The cost model
also takes subclasses and subproperties into account when determining the approximate cardinality of triple patterns.
</para>
<para>In essence, Virtuoso's support for subclasses and subproperties is backward chaining, i.e. it does not materialize
all implied triples but rather looks for the basic facts implying these triples at query evaluation time.
</para>
</sect2>
<sect2 id="rdfsparqlruleintro"><title>Enabling Inference</title>
<para>In a SPARQL query, the define input:inference clause is used to instruct the compiler to use the rules in the named rule set. For example:
</para>
<programlisting>
SQL> rdfs_rule_set ('sample', 'rule_graph');

SQL> sparql define input:inference "sample" select * from &lt;g&gt; where {?s ?p ?o};
</programlisting>
<para>will include all the implied triples in the result set, using the rules in the sample rule set.
</para>
<para>Inference can be enabled triple pattern by triple pattern. This is done with the option
(inference 'rule_set') clause after the triple pattern concerned. Specifying option (inference none)
will disable inference for the pattern concerned while the default inference context applies to the
rest of the patterns. Note that the keyword is input:inference in the query header and simply inference
in the option clause. See the examples section below for examples.
</para>
<para>In SQL, if RDF_QUAD occurs in a select from clause, inference can be added with the table option <emphasis>WITH</emphasis>, as follows:
</para>
<programlisting>
select * from rdf_quad table option (with 'sample') where g = iri_to_id ('xx', 0);
</programlisting>
<para>This is about the same as:
</para>
<programlisting>
define input:inference "sample" select * from &lt;xx&gt; where {?s ?p ?o}
</programlisting>
</sect2>
<sect2 id="rdfsparqlruleexamples"><title>Examples</title>
<programlisting>
ttlp ('
  &lt;ic1&gt; a &lt;c1&gt; .
  &lt;ic2&gt; a &lt;c2&gt; .
  &lt;ic3&gt; a &lt;c3&gt; .
  &lt;ic1&gt; &lt;p1&gt; &lt;ic1p1&gt; .
  &lt;ic2&gt; &lt;p1&gt; &lt;ic2p1&gt;.
  &lt;ic3&gt; &lt;p1&gt; &lt;ic3p1&gt; .
  &lt;ic1&gt; &lt;cl2&gt; &lt;c2&gt; .
  ', '', 'inft');
</programlisting>
<para>This loads a graph with some sample triples. The graph is called inft.
</para>
<programlisting>
ttlp (' @prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .
  &lt;c2&gt; rdfs:subClassOf &lt;c1&gt; .
  &lt;c3&gt; rdfs:subClassOf &lt;c2&gt; .
  &lt;c5&gt; rdfs:subClassOf &lt;c4&gt; .
  &lt;p1&gt; rdfs:subPropertyOf &lt;p0&gt; .
  ', '', 'sc');
</programlisting>
<para>This loads a graph called sc that contains assertions about subclasses and subproperties.
</para>
<programlisting>
rdfs_rule_set ('inft', 'sc');
</programlisting>
<para>This defines the rule context inft that is initialized from the contents of graph sc.
</para>
<programlisting>
sparql define input:inference 'inft' select ?s from &lt;inft&gt; where {?s a &lt;c1&gt; }
</programlisting>
<para>This returns the instances of c1. Since c2 and c3 are subclasses of c1, instances of
c1, c2 and c3 are all returned. This results in the subjects ic1, ic2 and ic3.
</para>
<programlisting>
select id_to_iri (s)
from rdf_quad table option (with 'inft')
where g = iri_to_id ('inft',0)
  and p = iri_to_id ('http://www.w3.org/1999/02/22-rdf-syntax-ns#type', 0)
  and o = iri_to_id ('c1', 0);
</programlisting>
<para>This is the corresponding SQL query, internally generated by the SPARQL query.

</para>
<para>Below we first look for all instances of c1 with some property set to ic2p1. We get the subject ic2 and the properties p1 and p0.
The join involves both subclass and subproperty inference. Then we turn off the inference for the second pattern and only get the
property p1. Then we do the same but now specify that inference should apply only to the first triple pattern.
</para>
<programlisting><![CDATA[

SQL> sparql define input:inference  'inft' select * from <inft> where { ?s ?p <c1> . ?s ?p1 <ic2p1> . };

s                                                                                 p                                                                                 p1
VARCHAR                                                                           VARCHAR                                                                           VARCHAR
_________________________

ic2                                                                               http://www.w3.org/1999/02/22-rdf-syntax-ns#type                                   p1
ic2                                                                               http://www.w3.org/1999/02/22-rdf-syntax-ns#type                                   p0

2 Rows. -- 0 msec.
SQL> sparql define input:inference  'inft' select * from <inft> where { ?s ?p <c1> . ?s ?p1 <ic2p1> option (inference 'none') . };
s                                                                                 p                                                                                 p1
VARCHAR                                                                           VARCHAR                                                                           VARCHAR
_______________________________________________________________________________

ic2                                                                               http://www.w3.org/1999/02/22-rdf-syntax-ns#type                                   p1

1 Rows. -- 0 msec.
SQL> sparql  select * from <inft> where { ?s ?p <c1> option (inference 'inft') . ?s ?p1 <ic2p1> . };
s                                                                                 p                                                                                 p1
VARCHAR                                                                           VARCHAR                                                                           VARCHAR
_______________________________________________________________________________

ic2                                                                               http://www.w3.org/1999/02/22-rdf-syntax-ns#type                                   p1

1 Rows. -- 0 msec.

]]></programlisting>
</sect2>
</sect1>
<sect1 id="rdfsparqlrulefulltext"><title>Using Full Text Search in SPARQL</title>
<para>Virtuoso's triple store supports optional full text indexing of RDF object values since version 5.0.
It is possible to declare that objects of triples with a given predicate or graph get indexed.
The graphs and triples may be enumerated or a wildcard may be used.
</para>
<para>The triples for which a full text index entry exists can be found using the <emphasis>bif:contains</emphasis>
or related filters and predicates.
</para>
<para>For example, the query:
</para>
<programlisting>
select *
  from &lt;people&gt;
 where {?s foaf:Name ?name . ?name bif_contains "rich*" .}
</programlisting>
<para>would match all subjects whose <emphasis>foaf:Name</emphasis> contained a word starting with Rich.
This would match Richard, Richie etc.
</para>
<para>If the <emphasis>bif:contains</emphasis> or related predicate is applied to an object that is not
a string or is not the object of an indexed triple, no match will be found.
</para>
<para>The syntax for text patterns is identical to the syntax for the SQL contains predicate.
</para>
<para>The SPARQL/SQL optimizer determines whether the text pattern will be used to drive the query or whether it
will filter results after other conditions are applied first. As opposed to <emphasis>bif:contains</emphasis>,
regexp matching never drives the query or makes us of an index, thus regexps are in practice checked after other conditions.
</para>
<sect2 id="rdfsparqlrulespecifywhatindex"><title>Specifying What to Index</title>
<para>Whether the object of a given triple is indexed in the text index depends on indexing rules. If at least one
indexing rule matches the triple, the object gets indexed if the object is a string. An indexing rule specifies
a graph and a predicate. Either may be an IRI or NULL, in which case it matches all IRI's.
</para>
<para>Rules also have a 'reason', which can be used to group rules into application-specific sets. A triple will stop
being indexed only after all rules mandating its indexing are removed. When an application requires indexing a
certain set of triples, rules are added to for the purpose. These rules are tagged with the name of the application
as their reason. When an application no longer requires indexing, the rules belonging to this application can be
removed. This will not turn off indexing if another application still needs certain triples to stay indexed.
</para>
<para>Indexing is enabled/disable for specific graph/predicate combinations with:
</para>
<programlisting>
create function DB.DBA.RDF_OBJ_FT_RULE_ADD
  (in rule_g varchar, in rule_p varchar, in reason varchar) returns integer
</programlisting>
<programlisting>
create function DB.DBA.RDF_OBJ_FT_RULE_DEL
  (in rule_g varchar, in rule_p varchar, in reason varchar) returns integer
</programlisting>
<para>The first function adds a rule. The two first arguments are the text representation of the IRI's for the graph
and predicate. If NULL is given then all graph's or predicates match. Specifying both as NULL means that all
string valued objects will be added to a text index.
</para>
<para>The second function reverses the effect of the first. Only a rule that actually has been added can be deleted.
Thus one cannot say that all except a certain enumerated set should be indexed.
</para>
<para>The reason argument is an arbitrary string identifying the application that needs this rule.
Two applications can add the same rule.
Removing one of them will still keep the rule in effect.
If an object is indexed due to more than one rule the index data remain free from duplicates, neither index size nor speed is affected.
</para>
<para>
If <emphasis>DB.DBA.RDF_OBJ_FT_RULE_ADD</emphasis> detects that the <emphasis>DB.DBA.RDF_QUAD</emphasis> contains quads whose graphs and/or predicates match to the new rule but not indexed before due to other rules then these quads are indexed automatically.
However the function <emphasis>DB.DBA.RDF_OBJ_FT_RULE_DEL</emphasis> does not remove indexing data about related objects.
Thus the presence of indexing data about an object does not imply that it is necessarily used in some quad that matches to some rule.
</para>
<para>Functions return one if the rule is added or deleted and zero if the call was redundant (the rule has been added before or there's no rule to delete).
</para>
<programlisting><![CDATA[

-- We load Tim Berners-Lee's FOAF file into a graph called people.

DB.DBA.RDF_LOAD_RDFXML (http_get ('http://www.w3.org/People/Berners-Lee/card#i'), 'no', 'people');

-- We check how many triples we got.

select count (*) from (sparql select * from <people> where {?s ?p ?o})f;

-- We specify that all string objects in the graph people should be text indexed.

DB.DBA.RDF_OBJ_FT_RULE_ADD ('people', null, 'people');

-- We update the text index. See below on how to keep the text index automatically updated.

DB.DBA.VT_INC_INDEX_DB_DBA_RDF_OBJ ();


-- We  ask for the subjects and predicates of all triples in <people> where the object is a string which contains a word beginning with TIM.

sparql select * from <people> where { ?s ?p ?o . ?o bif:contains '"TIM*"' .};

s                p                o
VARCHAR          VARCHAR          VARCHAR
_______________________________________________________________________________

http://no        http://purl.org/dc/elements/1.1/title  Tim Berners-Lee's FOAF file
http://www.w3.org/People/Berners-Lee/card#i  http://xmlns.com/foaf/0.1/name  Timothy Berners-Lee
http://www.w3.org/People/Berners-Lee/card#i  http://www.w3.org/2000/01/rdf-schema#label  Tim Berners-Lee
http://www.w3.org/People/Berners-Lee/card#i  http://xmlns.com/foaf/0.1/givenname  Timothy
http://www.w3.org/People/Berners-Lee/card#i  http://xmlns.com/foaf/0.1/nick  TimBL
http://www.w3.org/People/Berners-Lee/card#i  http://xmlns.com/foaf/0.1/nick  timbl
http://dig.csail.mit.edu/breadcrumbs/blog/4  http://purl.org/dc/elements/1.1/title  timbl's blog

7 Rows. -- 2 msec.
]]></programlisting>
<para>
The below query is identical with the above but uses a different syntax.
The filter syntax is more flexible in that it allows passing extra options to the contains predicate. These may be useful in the future.
</para>
<programlisting><![CDATA[
sparql select * from <people> where { ?s ?p ?o . filter (bif:contains(?o,  '"TIM*"')) };

]]></programlisting>
<note><title>Note:</title><para>It is better to upgrade to the latest version of Virtuoso before adding free-text rules for the first time.
The upgrade is especially advised in case of big amounts of texts to be indexed.
The reason is that the free-text index on RDF may be changed in future versions and automatic upgrade of an existing index data into new format may take much more time than indexing from scratch.</para></note>
<para>The table <emphasis>DB.DBA.RDF_OBJ_FT_RULES</emphasis> stores list of free-text index configuration rules.
</para>
<programlisting><![CDATA[
create table DB.DBA.RDF_OBJ_FT_RULES (
  ROFR_G varchar not null,       -- specific graph IRI or NULL for "all graphs"
  ROFR_P varchar not null,       -- specific predicate IRI or NULL for "all predicates"
  ROFR_REASON varchar not null,  -- identification string of a creator, preferably human-readable
  primary key (ROFR_G, ROFR_P, ROFR_REASON) );
]]></programlisting>
<para>
Applications may read from this table but they should not write directly.
Numerous duplicates in rules does not affect speed of free-text index operations because the content of the table is cached in memory in a special way,
Unlike the use of configuration functions, direct write to the table will not update that cache.
</para>
<para>
The table is convenient to search for rules added by a given application.
If a unique identification string is used during installation of an application when rules are added then it's easy to remove that rules by an uninstall.
</para>
</sect2>
<sect2 id="rdfsparqlruletimeindexing"><title>Time of Indexing</title>
<para>The triple store's text index is by default in manual batch mode. This means that changes in triples are periodically
reflected in the text index but are not maintained in strict synchrony. This is much more efficient than keeping the
indices in constant synchrony. This setting may be altered with the <emphasis>db.dba.vt_batch_update</emphasis> stored procedure.
</para>
<para>To force synchronization of the RDF text index, use:
</para>
<programlisting>
DB.DBA.VT_INC_INDEX_DB_DBA_RDF_OBJ ();
</programlisting>
<para>To set the text index to follow the triples in real time, use:
</para>
<programlisting>
DB.DBA.VT_BATCH_UPDATE ('DB.DBA.RDF_OBJ', 'ON', null);
</programlisting>
<para>To set the text index to be updated every 10 minutes, use:
</para>
<programlisting>
DB.DBA.VT_BATCH_UPDATE ('DB.DBA.RDF_OBJ', 'ON', 10);
</programlisting>
<para>To make the update always manual, specify NULL as the last argument above.
</para>
<para>
Additional problem related to free-text index of <emphasis>DB.DBA.RDF_QUAD</emphasis> is that some applications (e.g. import of billions of triples) may set triggers off.
This will make free-text index data incomplete.
Call of procedure <emphasis>DB.DBA.RDF_OBJ_FT_RECOVER ()</emphasis> will insert all missing free-text index items by drop and re-insert every existing free-text index rule.
</para>
</sect2>
<sect2 id="rdfviewsandfreetext"><title>Free-Text Indexes on RDF Views</title>
<para>
If an <emphasis>O</emphasis> field of a quad map pattern gets its value from a database column that have a free text index then this index can be used in SPARQL for efficient text search.
As a variant, the free-text index of an additional table may be used.
</para>
<para>
If a statement of quad map pattern declaration starts with declaration of table aliases, declaration of table alias may include name of table column that should have a text index.
Consider possible use of free-text index on content of DAV resources stored in DAV system tables of Virtuoso:
</para>
<programlisting><![CDATA[
prefix mydav: <...>
create quad storage mydav:metadata
from WS.WS.SYS_DAV_RES as dav_resource text literal RES_CONTENT
...
  {
    ...
    mydav:resource-iri (dav_resource.RES_FULL_PATH)
        a mydav:resource ;
        mydav:resource-content dav_resource.RES_CONTENT ;
        mydav:resource-mime-type dav_resource.RESTYPE ;
    ...
  }
]]></programlisting>
<para>
The clause <emphasis>text literal RES_CONTENT</emphasis> grants the SPARQL compiler permission to use free-text index for objects that are literals composed from column <emphasis>dav_resource.RES_CONTENT</emphasis>; this clause also choose between <emphasis>text literal</emphasis> (supports <emphasis>contains()</emphasis> predicate only) and <emphasis>text xml literal</emphasis> (supports both <emphasis>contains()</emphasis> and <emphasis>xcontains()</emphasis>) text indexes.
It is important to understand that free-text index will produce results using raw relational data.
If a literal class transformation changes the text stored in the column then these changes are ignored by free-text search.
E.g., a transformation concatenates a word to the value of the column, but the free-text search will not find this word.
</para>
<para>
The free-text index may be used in a more sophisticated way. Consider a built-in table <emphasis>DB.DBA.RDF_QUAD</emphasis> that does not have a free-text index.
Moreover, the table does not contain full values of all objects; the <emphasis>O</emphasis> column contains &quot;short enough&quot; values inlined, but long and special values are represented by links to <emphasis>DB.DBA.RDF_OBJ</emphasis> table.
The RDF_OBJ table, however, has free-text index that can be used.
The full declaration of built-in default mapping for default storage could be written this way:
</para>
<programlisting><![CDATA[
-- Important! Do not try to execute on live system
-- without prior changing names of storage and quad map pattern!

sparql
create virtrdf:DefaultQuadMap as
graph rdfdf:default-iid-nonblank (DB.DBA.RDF_QUAD.G)
subject rdfdf:default-iid (DB.DBA.RDF_QUAD.S)
predicate rdfdf:default-iid-nonblank (DB.DBA.RDF_QUAD.P)
object rdfdf:default (DB.DBA.RDF_QUAD.O)

create quad storage virtrdf:DefaultQuadStorage
from DB.DBA.RDF_QUAD as physical_quad
from DB.DBA.RDF_OBJ as physical_obj text xml literal RO_DIGEST of (physical_quad.O)
where (^{physical_quad.}^.O = ^{physical_obj.}^.RO_DIGEST)
  {
    create virtrdf:DefaultQuadMap as
      graph rdfdf:default-iid-nonblank (physical_quad.G)
      subject rdfdf:default-iid (physical_quad.S)
      predicate rdfdf:default-iid-nonblank (physical_quad.P)
      object rdfdf:default (physical_quad.O) .
  }
;
]]></programlisting>
<para>
The reference to the free-text index is extended by clause <emphasis> of (physical_quad.O)</emphasis>.
This means that the free-text on <emphasis>DB.DBA.RDF_OBJ.RO_DIGEST</emphasis> will be used when the object value comes from <emphasis>physical_quad.O</emphasis> as if <emphasis>physical_quad.O</emphasis> were indexed itself.
If a SPARQL query invokes <emphasis>virtrdf:DefaultQuadMap</emphasis> but contains no free-text criteria then only <emphasis>DB.DBA.RDF_QUAD</emphasis> appears in the final SQL statement and no join with <emphasis>DB.DBA.RDF_OBJ</emphasis> is made.
Adding a free-text predicate will add <emphasis>DB.DBA.RDF_OBJ</emphasis> to the list of source tables and a join condition for <emphasis>DB.DBA.RDF_QUAD.O</emphasis> and <emphasis>DB.DBA.RDF_OBJ.RO_DIGEST</emphasis>; and it will add <emphasis>contains (RO_DIGEST, ...)</emphasis> predicate, not <emphasis>contains (O, ...)</emphasis>.
As a result, &quot;you pay only for what you use&quot;: adding free-text index to the declaration does not add tables to the query unless the index is actually used.
</para>
<para>
Boolean functions <function>bif:contains</function> and <function>bif:xcontains</function> are used for objects that come from RDF Views as well as for regular &quot;physical&quot; triples.
Every function gets two arguments and returns a boolean value.
The first argument is an local variable.
The argument variable should be used as an object field in the group pattern where the filter condition is placed.
Moreover, the occurrence of variable in object field should be placed <emphasis>before</emphasis> the filter.
If there are many occurrences of the variable in object fields then the free-text search is associated with the rightmost occurrence that is still to the left from the filter.
The triple pattern that contains the rightmost occurrence is called &quot;intake&quot; of free-text search.
When SPARQL compiler chooses appropriate quad map patterns that may generate data matching intake triple pattern it skips quad map patterns that have no declared free-text indexes, because nothing can be found by free-text search in data that have no free-text index.
Every quad map pattern that has free-text pattern will finally produce an invocation of SQL <link linkend="containspredicate">contains</link> or <link linkend="xcontainspredicate">xcontains</link> predicate, so the whole result of free-text search may be a union of free-text searches from different quad map patterns.
</para>
<para>
The described logic is important only in really complicated cases whereas simple queries are self-evident:
</para>
<programlisting><![CDATA[
select * from <my-dav-graph>
where {
    ?resource a mydav:resource ;
        mydav:resource-content ?text .
    filter (bif:contains (?text, "hello and world")) }
]]></programlisting>
<para>
or, more compact,
</para>
<programlisting><![CDATA[
select * from <my-dav-graph>
where {
    ?resource a mydav:resource ;
        mydav:resource-content ?text .
    ?text bif:contains "hello and world" . }
]]></programlisting>
</sect2>
</sect1>

<sect1 id="rdfsparqlaggregate"><title>Aggregates in SPARQL</title>
<para>Virtuoso extends SPARQL with SQL like aggregate and group by functionality. This functionality is
also available through embedding SPARQL text inside SQL but the SPARQL extension syntax has the benefit
of working also over the SPARQL protocol and of looking more SPARQL-like.
</para>
<para>The supported aggregates are <emphasis>count</emphasis>, <emphasis>min</emphasis>, <emphasis>max</emphasis>,
<emphasis>avg</emphasis> and <emphasis>sum</emphasis>. These can take an optional <emphasis>distinct</emphasis>
keyword. These are permitted only in the selection part of a select query. If a selection list consists
of a mix of variables and aggregates, the non-aggregate selected items are considered to be grouping
columns and a group by over them is implicitly added at the end of the generated SQL query. There is
no explicit syntax for group by or having in Virtuoso SPARQL.
</para>
<para>If a selection consists of aggregates exclusively, the result set has one row with the values
of the aggregates. If there are aggregates and variables in the selection, the result set as has many
rows as there are distinct combinations of the variables and the aggregates are calculated over each
such distinct combination, as if there were a SQL group by over all non-aggregates.
</para>
<para>With the count aggregate the argument may be either <emphasis>*</emphasis>, meaning counting all rows or a variable
name, meaning counting all the rows where this variable is bound. If there is no implicit <emphasis>group by</emphasis>,
there can be an optional <emphasis>distinct</emphasis> keyword before the variable that is the argument of an aggregate.
</para>
<para>Because SPARQL does not have derived tables, there is a special syntax for counting distinct
combinations of selected variables. This is:
</para>
<programlisting><![CDATA[
select count distinct ?v1 ... ?vn
  from ....
]]></programlisting>
<sect2 id="rdfsparqlaggregateexamples"><title>Examples</title>
<programlisting><![CDATA[
sparql
select count (*)
  from <g>
 where {?s ?p ?o}

-- Returns the count of physical triples in g.
]]></programlisting>

<programlisting><![CDATA[
sparql define input:inference 'inft'
select ?p count (?o)
  from <inft>
 where {?s ?p ?o};

-- Returns the count of O's for each distinct P.
]]></programlisting>

<programlisting><![CDATA[
sparql define input:inference 'inft'
select count (?p) count (?o) count (distinct ?o)
 from <inft>
where {?s ?p ?o};

-- returns the count of triples, including inferred triples and the count of distinct O values.
]]></programlisting>

<programlisting><![CDATA[
select count distinct ?s ?p ?o
  from <g>
 where {?s ?p ?o}

-- Returns the number of distinct bindings of ?s ?p ?o.
]]></programlisting>
</sect2>
<sect2 id="rdfsparqlaggregatenote"><title>Note on Aggregates and Inference</title>
<para>Inference is added to a SPARQL query only for the variables whose value is actually used.Thus,
</para>
<programlisting><![CDATA[
select count (*)
 from <g>
where {?s ?p ?o}
]]></programlisting>
<para>will not make inferred values since s, p, and o are actually not used. Instead,
</para>
<programlisting><![CDATA[
select count (?s) count (?p) count (?o)
 from <g>
where {?s ?p ?o}
]]></programlisting>
<para>will get all the inferred triples also.
</para>
<para>
This may be confusing and will likely be corrected in the future.
</para>
</sect2>
</sect1>

<sect1 id="rdfsparqlprotocolendpoint"><title>Virtuoso SPARQL Query Service</title>
<sect2 id="rdfsparqlprotocolendpointintro"><title>Introduction</title>
<para>The Virtuoso SPARQL query service implements the <ulink url="http://www.w3.org/TR/rdf-sparql-protocol/">SPARQL Protocol for RDF</ulink>
(W3C Working Draft 25 January 2006) providing SPARQL query processing for RDF data available on the open internet.</para>
<para>The query processor extends the standard protocol to provide support for multiple output formats.
At present this uses additional query parameters.</para>
<para>Supported features include</para>
<itemizedlist mark="bullet" spacing="compact">
<listitem>GET and POST requests;</listitem>
<listitem>variety of transfer MIME-types, including RDF /XML and   TURTLE;</listitem>
<listitem>default-graph-uri environment parameter;</listitem>
<listitem>all sorts of queries including CONSTRUCT and DESCRIBE.</listitem>
</itemizedlist>
</sect2>

<sect2 id="rdfsupportedprotocolendpointuri"><title>Service Endpoint </title>
<para>Virtuoso reserves the path '/sparql/' and a synonym path '/SPARQL/' for SPARQL service.</para>
<para>In the current implementation, Virtuoso defines virtual directories for HTTP requests that come to the port
specified as 'ServerPort' in the '[HTTPServer]' section of Virtuoso configuration file and refer to one of these
two path strings. So if the Virtuoso installation on host example.com listens for HTTP requests on
port 8080 then client  applications should use the 'service endpoint' string equal to 'http://example.com:8080/sparql/'.</para>
<para>Both GET and POST requests are supported by both server and client. The server recognizes the 'Accept: ...' line of request header
to find MIME types preferred by the connected client and adjust the output mode of the response.</para>
<para>The client chooses between GET and POST automatically, using the length of query text as a criterion.</para>
<para>If the SPARQL endpoint is accessed without any url and query entered, will be shown page with interactive query form.</para>
</sect2>

<sect2 id="rdfsupportedrequestmethodsofprotocol"><title>Request Methods</title>
<table colsep="1" frame="all" rowsep="0" shortentry="0" tocentry="1" tabstyle="decimalstyle" orient="land" pgwide="0">
    <title>Methods List</title>
    <tgroup align="char" charoff="50" char="." cols="3">
    <colspec align="left" colnum="1" colsep="0" colwidth="20pc"/>
    <thead>
      <row>
        <entry>Method</entry>
        <entry>Supported?</entry>
        <entry>Notes</entry>
      </row>
    </thead>
    <tbody>
      <row>
        <entry>GET</entry>
        <entry>Yes</entry>
        <entry>short queries are sent in GET mode</entry>
      </row>
      <row>
        <entry>POST</entry>
        <entry>Yes</entry>
        <entry>Queries longer than 1900 bytes are POST-ed.</entry>
      </row>
      <row>
        <entry>DELETE</entry>
        <entry>No</entry>
        <entry></entry>
      </row>
      <row>
        <entry>PUT</entry>
        <entry>No</entry>
        <entry></entry>
      </row>
    </tbody>
  </tgroup>
</table>
</sect2>

<sect2 id="rdfsparqlclientfunctions"><title>Functions</title>
<para>The SPARQL client can be invoked by three similar functions:</para>

<table colsep="1" frame="all" rowsep="0" shortentry="0" tocentry="1" tabstyle="decimalstyle" orient="land" pgwide="0">
    <title>Functions List</title>
    <tgroup align="char" charoff="50" char="." cols="3">
    <colspec align="left" colnum="1" colsep="0" colwidth="20pc"/>
    <thead>
      <row>
        <entry>Function</entry>
        <entry>Notes</entry>
      </row>
    </thead>
    <tbody>
      <row>
        <entry>DB.DBA.SPARQL_REXEC</entry>
        <entry>behaves like DBA.SPARQL_EVAL, but executes the query on the specified server. The procedure does not return anything. Instead, it creates a result set. </entry>
      </row>
      <row>
        <entry>DB.DBA.SPARQL_REXEC_TO_ARRAY</entry>
        <entry>behaves like DBA.SPARQL_EXEC_TO_ARRAY (), but executes the query on the specified server. The function return a vector of rows, where every row is represented by a vector of values of fields.</entry>
      </row>
      <row>
        <entry>DB.DBA.SPARQL_REXEC_WITH_META</entry>
        <entry>has no local 'SPARQL_EVAL' analog. It produces not only an array of result rows but also array of metadata about result set in a format used by the exec () function. This function can be used when the result should be passed later to exec_result_names () and exec_result () built-in functions. To process local query in similar style, an application can use plain SQL built-in function exec (): an SPARQL query (with 'SPARQL' keyword in front) can be passed to exec () instead of text of plain SQL SELECT statement.</entry>
      </row>
    </tbody>
  </tgroup>
</table>

<programlisting>
create procedure DB.DBA.SPARQL_REXEC (
    in service varchar, in query varchar, in dflt_graph varchar, in named_graphs any,
    in req_hdr any, in maxrows integer, in bnode_dict any );
</programlisting>

<programlisting>
create function DB.DBA.SPARQL_REXEC_TO_ARRAY (
    in service varchar, in query varchar, in dflt_graph varchar, in named_graphs any,
    in req_hdr any, in maxrows integer, in bnode_dict any )
    returns any;
</programlisting>

<programlisting>
create procedure DB.DBA.SPARQL_REXEC_WITH_META (
    in service varchar, in query varchar, in dflt_graph varchar, in named_graphs any,
    in req_hdr any, in maxrows integer, in bnode_dict any,
    out metadata any,  -- metadata like exec () returns.
    out resultset any) -- results as 'long valmode' values.
</programlisting>

</sect2>

<sect2 id="rdfrequestparamsofunctions"><title>Request Parameters</title>
<table colsep="1" frame="all" rowsep="0" shortentry="0" tocentry="1" tabstyle="decimalstyle" orient="land" pgwide="0">
    <title>Request Parameters List</title>
    <tgroup align="char" charoff="50" char="." cols="3">
    <colspec align="left" colnum="1" colsep="0" colwidth="20pc"/>
    <thead>
      <row>
        <entry>Parameter</entry>
        <entry>Notes</entry>
        <entry>Required?</entry>
        <entry>Occurrence</entry>
      </row>
    </thead>
    <tbody>
      <row>
        <entry>service</entry>
        <entry>service URI such as 'http://example.com/sparql/'</entry>
        <entry>Yes</entry>
        <entry></entry>
      </row>
      <row>
        <entry>query</entry>
        <entry>text of the query</entry>
        <entry>Yes</entry>
        <entry></entry>
      </row>
      <row>
        <entry>dflt_graph</entry>
        <entry>default graph URI (string or NULL)</entry>
        <entry>No</entry>
        <entry></entry>
      </row>
      <row>
        <entry>named_graphs</entry>
        <entry>vector of named graphs (or NULL to not override what's specified in the query</entry>
        <entry>Yes</entry>
        <entry></entry>
      </row>
      <row>
        <entry>req_hdr</entry>
        <entry>additional HTTP header lines that should be passed to the service; 'Host: ...' is most popular</entry>
        <entry>No</entry>
        <entry></entry>
      </row>
      <row>
        <entry>maxrows</entry>
        <entry>limit on numbers of rows that should be returned (actual size of result set may differ)</entry>
        <entry>No</entry>
        <entry></entry>
      </row>
      <row>
        <entry>bnode_dict</entry>
        <entry>dictionary of known blank node names, or NULL for usual loading</entry>
        <entry>No</entry>
        <entry></entry>
      </row>
    </tbody>
  </tgroup>
</table>
</sect2>

<sect2 id="rdfresponsecodeofprotocol"><title>Response Codes</title>
<para>If the query is a CONSTRUCT or DESCRIBE then the result set
consists of a single row and a single column, the value inside is a
dictionary of triples in 'long valmode'. Note that the dictionary
object can not be sent to SQL client, say, via ODBC. The client can
loose database connection trying to fetch a result set row that
contain a dictionary object. This disconnect will be safe for server,
so the client can re-connect to the server, but the disconnected
transaction will be rolled back.</para>
</sect2>

<sect2 id="rdfsupportedmimesofprotocol"><title>Response Format</title>
<para>All standard MIME types of SPARQL Protocol are supported:</para>
<table colsep="1" frame="all" rowsep="0" shortentry="0" tocentry="1" tabstyle="decimalstyle" orient="land" pgwide="0">
    <title>Supported MIME Types list</title>
    <tgroup align="char" charoff="50" char="." cols="3">
    <colspec align="left" colnum="1" colsep="0" colwidth="20pc"/>
    <thead>
      <row>
        <entry>Mimetype</entry>
        <entry>Supported for result of Query</entry>
      </row>
    </thead>
    <tbody>
      <row>
        <entry>'application/sparql-results+xml'</entry>
        <entry>SELECT</entry>
      </row>
      <row>
        <entry>'application/sparql-results+xml'</entry>
        <entry>ASK</entry>
      </row>
      <row>
        <entry>'application/rdf+xml'</entry>
        <entry>CONSTRUCT</entry>
      </row>
      <row>
        <entry>'application/rdf+xml'</entry>
        <entry>DESCRIBE</entry>
      </row>
      <row>
        <entry>'text/rdf+n3'</entry>
        <entry>CONSTRUCT</entry>
      </row>
      <row>
        <entry>'text/rdf+n3'</entry>
        <entry>DESCRIBE</entry>
      </row>
    </tbody>
  </tgroup>
</table>
<para>If the HTTP header returned by the remote server does not contain 'Content-Type' line, the MIME type may be guessed from  the text of the returned body. </para>
<para>The current implementation does not support results of SELECT returned in RDF /XML, TURTLE or 'sparql-results-2'.</para>
<para>Error messages returned from the service are returned as XML documents, using the mime type application/xml. The documents consist of a single element containing an error message.</para>
</sect2>

<sect2 id="rdfsupportedmimesaddofprotocol"><title>Additional Response Formats -- SELECT</title>
<para>Use the format parameter to select one of the following alternate output formats:</para>

<table colsep="1" frame="all" rowsep="0" shortentry="0" tocentry="1" tabstyle="decimalstyle" orient="land" pgwide="0">
    <title>Additional Response formats list</title>
    <tgroup align="char" charoff="50" char="." cols="3">
    <colspec align="left" colnum="1" colsep="0" colwidth="20pc"/>
    <thead>
      <row>
        <entry>Format Value</entry>
        <entry>Description</entry>
        <entry>Mimetype</entry>
      </row>
    </thead>
    <tbody>
      <row>
        <entry>HTML</entry>
        <entry>HTML document containing query summary and tabular results</entry>
        <entry>text/html</entry>
      </row>
      <row>
        <entry>json</entry>
        <entry>JSON serialization of results. Conforms to the draft specification Serializing SPARQL Query Results in JSON</entry>
        <entry>application/sparql-results+json</entry>
      </row>
      <row>
        <entry>js</entry>
        <entry>Javascript serialization of results. Generates an HTML table with the CSS class sparql. The table contains a column indicating row number and additional columns for each query variable. Each query solution contributes one row of the table. Unbound variables are indicated with a non-breaking space in the appropriate table cells.</entry>
        <entry>application/javascript</entry>
      </row>
      <row>
        <entry>table</entry>
        <entry></entry>
        <entry>text/html</entry>
      </row>
      <row>
        <entry>XML</entry>
        <entry></entry>
        <entry>text/html</entry>
      </row>
      <row>
        <entry>TURTLE</entry>
        <entry></entry>
        <entry>text/html</entry>
      </row>
    </tbody>
  </tgroup>
</table>
</sect2>

<sect2 id="rdfsparqlendpointexamples"><title>Examples</title>
<para>Virtuoso's SPARQL Implementation Demo offers a live demonstration of Virtuoso's implementation of
<ulink url="http://www.w3.org/TR/rdf-dawg-uc/">DAWG's SPARQL test-suite</ulink>;
a collection of SPARQL query language use-cases that enable interactive and simplified testing of a Triple Store's implementation.
Can be found at 'http://example.com:8080/sparql_demo/' depending on the local Virtuoso Server Configuration, or live at <ulink url="http://demo.openlinksw.com/sparql_demo">Virtuoso Demo Server</ulink>.
</para>
</sect2>

<sect2 id="rdfsparqlendpointimplnotes"><title>Implementation Notes</title>
<para>This service has been implemented using <ulink url="http://docs.openlinksw.com/virtuoso">Virtuoso Server</ulink>.</para>
</sect2>

<sect2 id="rdftables"><title>Virtuoso Semantic Bank end point</title>
    <para>
	<emphasis>What is Piggy Bank?</emphasis>
    </para>
    <para>
	Piggy Bank is an extension to the Firefox Web browser that turns it into a Semantic Web browser, letting you make use of existing information on the Web in more useful and flexible ways not offered by the original Web sites.
    </para>
    <para></para>
    <para>
	<emphasis>What is Semantic Bank?</emphasis>
    </para>
    <para>
	Semantic Bank is the server companion of Piggy Bank that lets you persist, share and publish data collected by individuals, groups or communities. Here is a screen shot of one in action: 
    </para>
    <para></para>
    <para></para>
    <para>
	<emphasis>What can I do with this?</emphasis>
    </para>
    <para>
	A Semantic Bank allows you to:
    </para>
    <para></para>
    <para>
	persist your information remotely on a server. This is useful, for example, if you want to share data between two of your computers or to avoid losing it due to mistakes or failure. 
    </para>
    <para></para>
    <para>
	share information with other people. The ability to tag resources creates a powerful serendipitous categorization (as proven by things like del.icio.us or Flickr). 
    </para>
    <para></para>
    <para>
	lets you publish your information, both in the "pure" RDF form (for those who know how to make use of it) or to regular web pages, with the usual Longwell facetted browsing view of it 
    </para>
    <para></para>
    <para></para>
    <para>
	<emphasis>How can I help?</emphasis>
    </para>
    <para>
	Semantic Bank is an open source software and built around the spirit of open participation and collaboration.
    </para>
    <para>
	There are several ways you can help:
    </para>
    <itemizedlist mark="bullet" spacing="compact">
      <listitem>Install a Semantic Bank and lets us know about it, so that we can update the list of available Semantic Banks.</listitem>
      <listitem>Subscribe to our mailing lists to show your interest and give us feedback</listitem>
      <listitem>Report problems and ask for new features through our issue tracking system.</listitem>
      <listitem>Send us patches or fixes to the code</listitem>
    </itemizedlist>
    <para>
	<emphasis>Licensing and Legal Issues</emphasis>
    </para>
    <para>
	Semantic Bank is open source software and is licensed under the BSD license.
    </para>
    <para>
	<emphasis>Note</emphasis>, however, that this software ships with libraries that are not released under the same license; that we interpret their licensing terms to be compatible with ours and that we are redistributing them unmodified. For more information on the licensing terms of the libraries Semantic Bank depends on, please refer to the source code.
    </para>
    <para>
	<emphasis>Download location:</emphasis>
    </para>
    <para>
	<ulink url="http://simile.mit.edu/dist/semantic-bank/">"http://simile.mit.edu/dist/semantic-bank/</ulink>
    </para>
    <para>
	<emphasis>The Virtuoso Semantic Bank end point.</emphasis>
    </para>
    <para>
	Before you can publish, you must register with one or more Semantic Banks:
    </para>
    <itemizedlist mark="bullet" spacing="compact">
      <listitem>Invoke the menu command Tools » Piggy Bank » My Semantic Bank Accounts....</listitem>
      <listitem>Click Add... in the Semantic Bank Accounts dialog box.</listitem>
      <listitem>In the popup dialog box, type in the URL to the Virtuoso Semantic Bank you want to register with. Example: http://server_name:server_port/bank</listitem>
      <listitem>Enter an account a valid Virtuoso DAV user. (Note: currently we do not use encryption during authentication; do not use your precious password here.)</listitem>
      <listitem>Click OK, wait for the account to get registered, and then dismiss the Semantic Bank Accounts dialog box.</listitem>
      <listitem>To publish an item, just click the corresponding Publish button (much like how you save the item). To publish all the items being viewed, click the Publish All button.</listitem>
    </itemizedlist>
    <para>
	<emphasis>What is the Graph Name used by Virtuoso for the Triples from PiggyBank?</emphasis>
    </para>
    <para>
	http://simile.org/piggybank/&lt;piggybank-generated-name&gt;
    </para>
    <para>
	    The piggybank-generated-name is Virtuoso DAV user.
    </para>
</sect2>
<sect2 id="rdfproxyservice"><title>RDF proxy service</title>
    <para>
	In certain cases like for Ajax applications, it's prohibited to issue HTTP requests to another server that origin server.
	In other cases it is needed to transform the content of target to an RDF format. To this purpose the Virtuoso Server provide a RDF proxy service. This service takes as argument target URL and may return content as-is or will try to transform with SPARQL sponger and return RDF data representing the target.  In case of transformation to RDF the serialization of the output can be forced by a URL parameter of by content negotiation.
    </para>
    <para>
	Virtuoso reserves the path '/proxy/' for RDF proxy service. In the current implementation, Virtuoso defines virtual directories for HTTP requests that come to the port specified as 'ServerPort' in the '[HTTPServer]' section of Virtuoso configuration file and refer to the above path string. So if the Virtuoso installation on host example.com listens for HTTP requests on port 8080 then client applications should use the 'service endpoint' string equal to 'http://example.com:8080/proxy/'.
    </para>
    <para>
	The RDF proxy service takes following URL parameters:
    </para>
    <itemizedlist mark="bullet" spacing="compact">
	<listitem><emphasis>url</emphasis> the URL of the target</listitem>
	<listitem><emphasis>force</emphasis> if 'rdf' is specified will try to extract RDF data from target and return it</listitem>
	<listitem><emphasis>header</emphasis> HTTP headers to be sent to the target</listitem>
	<listitem><emphasis>output-format</emphasis> if 'force=rdf' is given, designate the output MIME type of the RDF data, the default is 'rdf+xml', can be also 'n3' or 'turtle' or 'ttl'.</listitem>
    </itemizedlist>
    <para>
	When no 'output-format' is given and RDF data is asked, the result will be serialized with MIME type depending of 'Accept' header i.e. the proxy service will do content negotiation. 
    </para>
</sect2>
</sect1>
</chapter>
